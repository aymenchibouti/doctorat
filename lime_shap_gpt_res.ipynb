{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoUT8Cl21gSNPme/JMHMyJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymenchibouti/doctorat/blob/main/lime_shap_gpt_res.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PpkOik3h0mi",
        "outputId": "ef4348e6-6229-4695-d45f-4f3ab91fe126"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m194.6/275.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=a4f384d9494633ecd919eb9a665f5eceb7fdf142dbdec53135f8bb0fbc4f32ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-DaXfVhhDgg",
        "outputId": "8e4564b3-2166-4f85-fb05-0b75fabad356"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation for Logistic Regression:\n",
            "Accuracy: 0.8579\n",
            "Precision: 0.8669\n",
            "Recall: 0.9690\n",
            "F1 Score: 0.9151\n",
            "--------------------------------------------------\n",
            "Evaluation for Random Forest:\n",
            "Accuracy: 0.8595\n",
            "Precision: 0.8870\n",
            "Recall: 0.9422\n",
            "F1 Score: 0.9138\n",
            "--------------------------------------------------\n",
            "Evaluation for XGBoost:\n",
            "Accuracy: 0.8629\n",
            "Precision: 0.8814\n",
            "Recall: 0.9550\n",
            "F1 Score: 0.9167\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'model1_210_features.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop non-numeric columns that are not useful for prediction\n",
        "data = data.drop(columns=['username', 'course_id', 'enrollment_id'])\n",
        "\n",
        "# Handle missing values (fill with 0 or use mean/median imputation as necessary)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(columns=['dropout'])  # Features\n",
        "y = data['dropout']  # Target variable\n",
        "\n",
        "# Standardize the features (important for models like Logistic Regression and XGBoost)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train models\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "models = [lr, rf, xgb_model]\n",
        "model_names = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
        "\n",
        "for model, name in zip(models, model_names):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Evaluation for {name}:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Explainability using SHAP (SHAP can work with tree-based models like RandomForest and XGBoost)\n",
        "explainer_rf = shap.TreeExplainer(rf)\n",
        "shap_values_rf = explainer_rf.shap_values(X_test)\n",
        "\n",
        "# SHAP summary plot for Random Forest\n",
        "shap.summary_plot(shap_values_rf, X_test, feature_names=X.columns)\n",
        "\n",
        "# LIME - Local Interpretable Model-Agnostic Explanations\n",
        "explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train,\n",
        "    training_labels=y_train,\n",
        "    mode=\"classification\",\n",
        "    feature_names=X.columns,\n",
        "    class_names=[\"No Dropout\", \"Dropout\"],\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Pick a single instance for LIME explanation\n",
        "instance = X_test[0]  # First instance in the test set\n",
        "explanation_lime = explainer_lime.explain_instance(instance, xgb_model.predict_proba)\n",
        "\n",
        "# Visualize LIME explanation\n",
        "explanation_lime.show_in_notebook()\n",
        "\n",
        "# Feature Importance (using Random Forest)\n",
        "feature_importance = rf.feature_importances_\n",
        "# Visualize the feature importance\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(X.columns, feature_importance)\n",
        "plt.title(\"Feature Importance (Random Forest)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n"
      ]
    }
  ]
}