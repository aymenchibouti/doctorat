{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaG7a33Fnxruz+FV8ReZ6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymenchibouti/doctorat/blob/main/deep_ensemble_97_features_res.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "FuIRr8MlpEpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "m7ScKnHAm1O5",
        "outputId": "eb27d597-7033-445a-ceab-c525de6299a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Starting Ultra-High Accuracy Training Pipeline...\n",
            "============================================================\n",
            "üìä Preparing data with advanced preprocessing...\n",
            "üîß Engineering premium features for maximum accuracy...\n",
            "‚úÖ Created 31 premium features\n",
            "üìà Training set: 96433 samples\n",
            "üìâ Test set: 24109 samples\n",
            "‚öñÔ∏è Class distribution - Dropout: 76464 (79.3%)\n",
            "üöÄ Training high-performance base models...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Training CatBoost...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training SVM...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must have at least 1 validation dataset for early stopping.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2890041551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üöÄ High-Accuracy Dropout Predictor Ready!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-2890041551.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Train base models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_base_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# Create meta-ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-2890041551.py\u001b[0m in \u001b[0;36mtrain_base_models\u001b[0;34m(self, X_train, y_train, X_train_scaled)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# Use original data for tree-based models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_meta_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             )\n\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1683\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_eval_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_eval_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Must have at least 1 validation dataset for early stopping.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;31m# Get data name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must have at least 1 validation dataset for early stopping."
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class HighAccuracyDropoutPredictor:\n",
        "    \"\"\"\n",
        "    Ultra-high accuracy dropout prediction system using advanced ensemble methods\n",
        "    Target: >90% accuracy on student dropout prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.ensemble_model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names = []\n",
        "        self.is_trained = False\n",
        "\n",
        "    def engineer_premium_features(self, df):\n",
        "        \"\"\"\n",
        "        Create advanced features with highest predictive power\n",
        "        \"\"\"\n",
        "        print(\"üîß Engineering premium features for maximum accuracy...\")\n",
        "\n",
        "        # Activity types\n",
        "        activity_types = ['access', 'problem', 'wiki', 'discussion', 'navigate', 'page_close', 'video']\n",
        "\n",
        "        # Calculate daily totals\n",
        "        daily_totals = {}\n",
        "        for day in range(1, 31):\n",
        "            daily_total = 0\n",
        "            for activity in activity_types:\n",
        "                col_name = f'day_{day}_{activity}'\n",
        "                if col_name in df.columns:\n",
        "                    daily_total += df[col_name].fillna(0)\n",
        "            daily_totals[f'day_{day}_total'] = daily_total\n",
        "\n",
        "        # Convert to DataFrame for easier manipulation\n",
        "        daily_df = pd.DataFrame(daily_totals)\n",
        "\n",
        "        # TIER 1: CRITICAL EARLY INDICATORS (Highest Predictive Power)\n",
        "        features = pd.DataFrame()\n",
        "\n",
        "        # Day 2-3 engagement (strongest predictors)\n",
        "        features['day2_total'] = daily_df['day_2_total']\n",
        "        features['day3_total'] = daily_df['day_3_total']\n",
        "        features['day2_engaged'] = (daily_df['day_2_total'] > 0).astype(int)\n",
        "        features['day3_engaged'] = (daily_df['day_3_total'] > 0).astype(int)\n",
        "        features['day2_day3_combined'] = features['day2_total'] + features['day3_total']\n",
        "\n",
        "        # First week patterns\n",
        "        week1_cols = [f'day_{day}_total' for day in range(1, 8)]\n",
        "        features['week1_total'] = daily_df[week1_cols].sum(axis=1)\n",
        "        features['week1_active_days'] = (daily_df[week1_cols] > 0).sum(axis=1)\n",
        "        features['week1_consistency'] = features['week1_active_days'] / 7\n",
        "        features['week1_avg_when_active'] = features['week1_total'] / features['week1_active_days'].replace(0, 1)\n",
        "\n",
        "        # TIER 2: ADVANCED BEHAVIORAL PATTERNS\n",
        "\n",
        "        # Problem-solving engagement (strong completion predictor)\n",
        "        problem_cols = [col for col in df.columns if 'problem' in col and col != 'dropout']\n",
        "        if problem_cols:\n",
        "            features['total_problems'] = df[problem_cols].fillna(0).sum(axis=1)\n",
        "            features['early_problems'] = df[[col for col in problem_cols if any(f'day_{d}_' in col for d in range(1, 8))]].fillna(0).sum(axis=1)\n",
        "            features['problem_days'] = (df[problem_cols].fillna(0) > 0).sum(axis=1)\n",
        "            features['problem_consistency'] = features['problem_days'] / 30\n",
        "\n",
        "        # Video engagement patterns\n",
        "        video_cols = [col for col in df.columns if 'video' in col]\n",
        "        if video_cols:\n",
        "            features['total_videos'] = df[video_cols].fillna(0).sum(axis=1)\n",
        "            features['early_videos'] = df[[col for col in video_cols if any(f'day_{d}_' in col for d in range(1, 8))]].fillna(0).sum(axis=1)\n",
        "            features['video_engagement_ratio'] = features['total_videos'] / (features['week1_total'] + 1)\n",
        "\n",
        "        # Access patterns (general engagement)\n",
        "        access_cols = [col for col in df.columns if 'access' in col]\n",
        "        if access_cols:\n",
        "            features['total_access'] = df[access_cols].fillna(0).sum(axis=1)\n",
        "            features['early_access'] = df[[col for col in access_cols if any(f'day_{d}_' in col for d in range(1, 8))]].fillna(0).sum(axis=1)\n",
        "\n",
        "        # TIER 3: TEMPORAL AND CONSISTENCY FEATURES\n",
        "\n",
        "        # Overall activity patterns\n",
        "        features['total_activity'] = daily_df.sum(axis=1)\n",
        "        features['active_days_total'] = (daily_df > 0).sum(axis=1)\n",
        "        features['activity_per_active_day'] = features['total_activity'] / features['active_days_total'].replace(0, 1)\n",
        "        features['max_daily_activity'] = daily_df.max(axis=1)\n",
        "\n",
        "        # Early dropout signals\n",
        "        features['day1_to_day2_ratio'] = features['day2_total'] / (daily_df['day_1_total'] + 1)\n",
        "        features['early_engagement_drop'] = (daily_df['day_1_total'] - features['day2_total']).clip(lower=0)\n",
        "        features['sustained_beyond_day3'] = (daily_df[[f'day_{day}_total' for day in range(4, 15)]] > 0).sum(axis=1)\n",
        "\n",
        "        # Week-over-week patterns\n",
        "        week2_cols = [f'day_{day}_total' for day in range(8, 15)]\n",
        "        features['week2_total'] = daily_df[week2_cols].sum(axis=1)\n",
        "        features['week1_to_week2_decline'] = (features['week1_total'] - features['week2_total']).clip(lower=0) / (features['week1_total'] + 1)\n",
        "\n",
        "        # TIER 4: ADVANCED INTERACTION FEATURES\n",
        "\n",
        "        # Create interaction features between most important predictors\n",
        "        features['day2_week1_interaction'] = features['day2_engaged'] * features['week1_total']\n",
        "        features['problem_video_balance'] = features['total_problems'] * features['total_videos']\n",
        "        features['consistency_activity_interaction'] = features['week1_consistency'] * features['week1_total']\n",
        "\n",
        "        # Risk scoring based on multiple factors\n",
        "        features['early_risk_score'] = (\n",
        "            (features['day2_engaged'] == 0) * 3 +\n",
        "            (features['day3_engaged'] == 0) * 2 +\n",
        "            (features['week1_active_days'] <= 2) * 2 +\n",
        "            (features['total_problems'] == 0) * 2 +\n",
        "            (features['sustained_beyond_day3'] <= 1) * 1\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Created {len(features.columns)} premium features\")\n",
        "        return features\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"\n",
        "        Prepare data with advanced preprocessing\n",
        "        \"\"\"\n",
        "        print(\"üìä Preparing data with advanced preprocessing...\")\n",
        "\n",
        "        # Engineer premium features\n",
        "        X = self.engineer_premium_features(df)\n",
        "        y = df['dropout'].values\n",
        "\n",
        "        # Handle any remaining missing values\n",
        "        X = X.fillna(0)\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = X.columns.tolist()\n",
        "\n",
        "        # Stratified split to maintain class distribution\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale features for models that benefit from it\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        print(f\"üìà Training set: {len(X_train)} samples\")\n",
        "        print(f\"üìâ Test set: {len(X_test)} samples\")\n",
        "        print(f\"‚öñÔ∏è Class distribution - Dropout: {np.sum(y_train)} ({np.mean(y_train)*100:.1f}%)\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled\n",
        "\n",
        "    def train_base_models(self, X_train, y_train, X_train_scaled):\n",
        "        \"\"\"\n",
        "        Train multiple high-performance base models\n",
        "        \"\"\"\n",
        "        print(\"üöÄ Training high-performance base models...\")\n",
        "\n",
        "        # Model 1: XGBoost (typically best for structured data)\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['xgb'] = xgb.XGBClassifier(\n",
        "            n_estimators=500,\n",
        "            max_depth=8,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42,\n",
        "            eval_metric='logloss',\n",
        "            early_stopping_rounds=50\n",
        "        )\n",
        "\n",
        "        # Model 2: LightGBM (fast and accurate)\n",
        "        print(\"Training LightGBM...\")\n",
        "        self.models['lgb'] = lgb.LGBMClassifier(\n",
        "            n_estimators=500,\n",
        "            max_depth=8,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42,\n",
        "            verbose=-1\n",
        "        )\n",
        "\n",
        "        # Model 3: CatBoost (handles categorical features well)\n",
        "        print(\"Training CatBoost...\")\n",
        "        self.models['catboost'] = CatBoostClassifier(\n",
        "            iterations=500,\n",
        "            depth=8,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Model 4: Random Forest (robust ensemble)\n",
        "        print(\"Training Random Forest...\")\n",
        "        self.models['rf'] = RandomForestClassifier(\n",
        "            n_estimators=300,\n",
        "            max_depth=15,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Model 5: Gradient Boosting\n",
        "        print(\"Training Gradient Boosting...\")\n",
        "        self.models['gb'] = GradientBoostingClassifier(\n",
        "            n_estimators=300,\n",
        "            max_depth=8,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Model 6: Logistic Regression (linear baseline)\n",
        "        print(\"Training Logistic Regression...\")\n",
        "        self.models['lr'] = LogisticRegression(\n",
        "            C=1.0,\n",
        "            random_state=42,\n",
        "            max_iter=1000\n",
        "        )\n",
        "\n",
        "        # Model 7: SVM (for complex decision boundaries)\n",
        "        print(\"Training SVM...\")\n",
        "        self.models['svm'] = SVC(\n",
        "            C=1.0,\n",
        "            kernel='rbf',\n",
        "            probability=True,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Train models\n",
        "        for name, model in self.models.items():\n",
        "            if name in ['lr', 'svm']:\n",
        "                # Use scaled data for linear models\n",
        "                model.fit(X_train_scaled, y_train)\n",
        "            else:\n",
        "                # Use original data for tree-based models\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "    def create_meta_ensemble(self, X_train, y_train, X_train_scaled):\n",
        "        \"\"\"\n",
        "        Create advanced meta-ensemble for maximum accuracy\n",
        "        \"\"\"\n",
        "        print(\"üéØ Creating meta-ensemble for maximum accuracy...\")\n",
        "\n",
        "        # Get cross-validation predictions from base models\n",
        "        cv_predictions = np.zeros((len(X_train), len(self.models)))\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
        "            print(f\"Processing fold {fold + 1}/5...\")\n",
        "\n",
        "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "            X_fold_train_scaled, X_fold_val_scaled = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "            for i, (name, model) in enumerate(self.models.items()):\n",
        "                # Clone model\n",
        "                if name == 'xgb':\n",
        "                    fold_model = xgb.XGBClassifier(**model.get_params())\n",
        "                elif name == 'lgb':\n",
        "                    fold_model = lgb.LGBMClassifier(**model.get_params())\n",
        "                elif name == 'catboost':\n",
        "                    fold_model = CatBoostClassifier(**model.get_params())\n",
        "                else:\n",
        "                    fold_model = model.__class__(**model.get_params())\n",
        "\n",
        "                # Train and predict\n",
        "                if name in ['lr', 'svm']:\n",
        "                    fold_model.fit(X_fold_train_scaled, y_fold_train)\n",
        "                    cv_predictions[val_idx, i] = fold_model.predict_proba(X_fold_val_scaled)[:, 1]\n",
        "                else:\n",
        "                    fold_model.fit(X_fold_train, y_fold_train)\n",
        "                    cv_predictions[val_idx, i] = fold_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        # Train meta-classifier on CV predictions\n",
        "        print(\"Training meta-classifier...\")\n",
        "        self.meta_classifier = LogisticRegression(random_state=42)\n",
        "        self.meta_classifier.fit(cv_predictions, y_train)\n",
        "\n",
        "        # Also create a voting ensemble as backup\n",
        "        voting_models = [\n",
        "            ('xgb', self.models['xgb']),\n",
        "            ('lgb', self.models['lgb']),\n",
        "            ('catboost', self.models['catboost']),\n",
        "            ('rf', self.models['rf'])\n",
        "        ]\n",
        "\n",
        "        self.voting_ensemble = VotingClassifier(\n",
        "            estimators=voting_models,\n",
        "            voting='soft'\n",
        "        )\n",
        "\n",
        "        self.is_trained = True\n",
        "        print(\"‚úÖ Meta-ensemble training completed!\")\n",
        "\n",
        "    def predict_meta_ensemble(self, X_test, X_test_scaled):\n",
        "        \"\"\"\n",
        "        Make predictions using meta-ensemble\n",
        "        \"\"\"\n",
        "        # Get predictions from all base models\n",
        "        base_predictions = np.zeros((len(X_test), len(self.models)))\n",
        "\n",
        "        for i, (name, model) in enumerate(self.models.items()):\n",
        "            if name in ['lr', 'svm']:\n",
        "                base_predictions[:, i] = model.predict_proba(X_test_scaled)[:, 1]\n",
        "            else:\n",
        "                base_predictions[:, i] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Use meta-classifier to combine predictions\n",
        "        meta_probabilities = self.meta_classifier.predict_proba(base_predictions)[:, 1]\n",
        "        meta_predictions = (meta_probabilities > 0.5).astype(int)\n",
        "\n",
        "        return meta_predictions, meta_probabilities\n",
        "\n",
        "    def evaluate_model(self, y_true, y_pred, y_prob=None):\n",
        "        \"\"\"\n",
        "        Comprehensive model evaluation\n",
        "        \"\"\"\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "        # Calculate specificity and balanced accuracy\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        specificity = tn / (tn + fp)\n",
        "        balanced_accuracy = (recall + specificity) / 2\n",
        "\n",
        "        results = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'specificity': specificity,\n",
        "            'balanced_accuracy': balanced_accuracy,\n",
        "            'confusion_matrix': {'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn}\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def train_and_evaluate(self, df):\n",
        "        \"\"\"\n",
        "        Complete training and evaluation pipeline\n",
        "        \"\"\"\n",
        "        print(\"üéØ Starting Ultra-High Accuracy Training Pipeline...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Prepare data\n",
        "        X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled = self.prepare_data(df)\n",
        "\n",
        "        # Train base models\n",
        "        self.train_base_models(X_train, y_train, X_train_scaled)\n",
        "\n",
        "        # Create meta-ensemble\n",
        "        self.create_meta_ensemble(X_train, y_train, X_train_scaled)\n",
        "\n",
        "        # Evaluate individual models\n",
        "        print(\"\\nüìä Individual Model Performance:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        individual_results = {}\n",
        "        for name, model in self.models.items():\n",
        "            if name in ['lr', 'svm']:\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "                y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
        "            else:\n",
        "                y_pred = model.predict(X_test)\n",
        "                y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "            results = self.evaluate_model(y_test, y_pred, y_prob)\n",
        "            individual_results[name] = results\n",
        "\n",
        "            print(f\"{name.upper():>12}: Accuracy={results['accuracy']:.4f}, F1={results['f1_score']:.4f}\")\n",
        "\n",
        "        # Evaluate meta-ensemble\n",
        "        print(\"\\nüèÜ META-ENSEMBLE PERFORMANCE:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        meta_pred, meta_prob = self.predict_meta_ensemble(X_test, X_test_scaled)\n",
        "        meta_results = self.evaluate_model(y_test, meta_pred, meta_prob)\n",
        "\n",
        "        print(f\"üéØ ACCURACY: {meta_results['accuracy']:.4f} ({meta_results['accuracy']*100:.2f}%)\")\n",
        "        print(f\"‚öñÔ∏è BALANCED ACCURACY: {meta_results['balanced_accuracy']:.4f} ({meta_results['balanced_accuracy']*100:.2f}%)\")\n",
        "        print(f\"üìä PRECISION: {meta_results['precision']:.4f} ({meta_results['precision']*100:.2f}%)\")\n",
        "        print(f\"üîç RECALL: {meta_results['recall']:.4f} ({meta_results['recall']*100:.2f}%)\")\n",
        "        print(f\"üõ°Ô∏è SPECIFICITY: {meta_results['specificity']:.4f} ({meta_results['specificity']*100:.2f}%)\")\n",
        "        print(f\"üìà F1-SCORE: {meta_results['f1_score']:.4f} ({meta_results['f1_score']*100:.2f}%)\")\n",
        "\n",
        "        print(f\"\\nüìã Confusion Matrix:\")\n",
        "        cm = meta_results['confusion_matrix']\n",
        "        print(f\"   Predicted:    Dropout  Complete\")\n",
        "        print(f\"   Actual Dropout:  {cm['tp']:>6}    {cm['fn']:>6}\")\n",
        "        print(f\"   Actual Complete: {cm['fp']:>6}    {cm['tn']:>6}\")\n",
        "\n",
        "        # Success message\n",
        "        if meta_results['accuracy'] >= 0.90:\n",
        "            print(f\"\\nüéâüéâüéâ MISSION ACCOMPLISHED! üéâüéâüéâ\")\n",
        "            print(f\"‚úÖ Achieved {meta_results['accuracy']*100:.2f}% accuracy - EXCEEDED 90% TARGET!\")\n",
        "            print(f\"üèÜ This model successfully predicts student dropouts with high confidence!\")\n",
        "        else:\n",
        "            print(f\"\\nüìà EXCELLENT PROGRESS!\")\n",
        "            print(f\"Current accuracy: {meta_results['accuracy']*100:.2f}%\")\n",
        "            print(f\"Very close to 90% target!\")\n",
        "\n",
        "        return {\n",
        "            'individual_results': individual_results,\n",
        "            'meta_results': meta_results,\n",
        "            'feature_names': self.feature_names\n",
        "        }\n",
        "\n",
        "# Usage Example:\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your data\n",
        "    df = pd.read_csv('model1_210_features.csv')\n",
        "\n",
        "    # Initialize and train the predictor\n",
        "    predictor = HighAccuracyDropoutPredictor()\n",
        "\n",
        "    # Train and evaluate\n",
        "    results = predictor.train_and_evaluate(df)\n",
        "\n",
        "    print(\"üöÄ High-Accuracy Dropout Predictor Ready!\")\n",
        "    print(\"üìù Load your CSV file and call: results = predictor.train_and_evaluate(df)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, optimizers\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "class DeepLearningDropoutPredictor:\n",
        "    \"\"\"\n",
        "    Advanced Deep Learning System for Student Dropout Prediction\n",
        "    Utilizes neural networks with attention mechanisms and advanced architectures\n",
        "    Target: >90% accuracy with robust generalization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.ensemble_models = []\n",
        "        self.scaler = RobustScaler()  # More robust to outliers\n",
        "        self.feature_names = []\n",
        "        self.history = None\n",
        "        self.is_trained = False\n",
        "\n",
        "    def engineer_deep_features(self, df):\n",
        "        \"\"\"\n",
        "        Engineer features specifically designed for deep learning\n",
        "        \"\"\"\n",
        "        print(\"üß† Engineering features for deep learning...\")\n",
        "\n",
        "        activity_types = ['access', 'problem', 'wiki', 'discussion', 'navigate', 'page_close', 'video']\n",
        "\n",
        "        # Create daily activity matrix (30 days x 7 activities = 210 features)\n",
        "        daily_features = []\n",
        "        for day in range(1, 31):\n",
        "            for activity in activity_types:\n",
        "                col_name = f'day_{day}_{activity}'\n",
        "                if col_name in df.columns:\n",
        "                    daily_features.append(df[col_name].fillna(0))\n",
        "                else:\n",
        "                    daily_features.append(pd.Series(np.zeros(len(df))))\n",
        "\n",
        "        # Stack into matrix\n",
        "        daily_matrix = np.column_stack(daily_features)\n",
        "\n",
        "        # Calculate advanced temporal features\n",
        "        features_dict = {}\n",
        "\n",
        "        # 1. Raw daily totals (first 14 days - most predictive period)\n",
        "        for day in range(1, 15):\n",
        "            day_total = 0\n",
        "            for activity in activity_types:\n",
        "                col_name = f'day_{day}_{activity}'\n",
        "                if col_name in df.columns:\n",
        "                    day_total += df[col_name].fillna(0)\n",
        "            features_dict[f'day_{day}_total'] = day_total\n",
        "\n",
        "        # 2. Weekly aggregations\n",
        "        week_features = ['total', 'mean', 'std', 'max']\n",
        "        for week in range(1, 5):  # 4 weeks\n",
        "            start_day = (week - 1) * 7 + 1\n",
        "            end_day = min(week * 7, 30)\n",
        "\n",
        "            week_data = []\n",
        "            for day in range(start_day, end_day + 1):\n",
        "                day_total = 0\n",
        "                for activity in activity_types:\n",
        "                    col_name = f'day_{day}_{activity}'\n",
        "                    if col_name in df.columns:\n",
        "                        day_total += df[col_name].fillna(0)\n",
        "                week_data.append(day_total)\n",
        "\n",
        "            week_df = pd.DataFrame(week_data).T\n",
        "            features_dict[f'week_{week}_total'] = week_df.sum(axis=1)\n",
        "            features_dict[f'week_{week}_mean'] = week_df.mean(axis=1)\n",
        "            features_dict[f'week_{week}_std'] = week_df.std(axis=1).fillna(0)\n",
        "            features_dict[f'week_{week}_max'] = week_df.max(axis=1)\n",
        "\n",
        "        # 3. Activity-specific aggregations\n",
        "        for activity in activity_types:\n",
        "            activity_cols = [col for col in df.columns if f'_{activity}' in col and col != 'dropout']\n",
        "            if activity_cols:\n",
        "                activity_data = df[activity_cols].fillna(0)\n",
        "                features_dict[f'{activity}_total'] = activity_data.sum(axis=1)\n",
        "                features_dict[f'{activity}_mean'] = activity_data.mean(axis=1)\n",
        "                features_dict[f'{activity}_max'] = activity_data.max(axis=1)\n",
        "                features_dict[f'{activity}_days_active'] = (activity_data > 0).sum(axis=1)\n",
        "\n",
        "                # Early vs late activity\n",
        "                early_cols = [col for col in activity_cols if any(f'day_{d}_' in col for d in range(1, 8))]\n",
        "                late_cols = [col for col in activity_cols if any(f'day_{d}_' in col for d in range(8, 31))]\n",
        "\n",
        "                if early_cols:\n",
        "                    features_dict[f'{activity}_early'] = df[early_cols].fillna(0).sum(axis=1)\n",
        "                if late_cols:\n",
        "                    features_dict[f'{activity}_late'] = df[late_cols].fillna(0).sum(axis=1)\n",
        "\n",
        "        # 4. Temporal patterns and trends\n",
        "        daily_totals = []\n",
        "        for day in range(1, 31):\n",
        "            day_total = 0\n",
        "            for activity in activity_types:\n",
        "                col_name = f'day_{day}_{activity}'\n",
        "                if col_name in df.columns:\n",
        "                    day_total += df[col_name].fillna(0)\n",
        "            daily_totals.append(day_total)\n",
        "\n",
        "        daily_totals_df = pd.DataFrame(daily_totals).T\n",
        "\n",
        "        # Activity trend (slope of activity over time)\n",
        "        features_dict['activity_trend'] = daily_totals_df.apply(\n",
        "            lambda row: np.polyfit(range(len(row)), row, 1)[0] if row.sum() > 0 else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Peak activity day\n",
        "        features_dict['peak_activity_day'] = daily_totals_df.apply(lambda row: row.argmax() + 1, axis=1)\n",
        "        features_dict['peak_activity_value'] = daily_totals_df.max(axis=1)\n",
        "\n",
        "        # Activity consistency (coefficient of variation)\n",
        "        features_dict['activity_consistency'] = daily_totals_df.apply(\n",
        "            lambda row: row.std() / (row.mean() + 1e-8), axis=1\n",
        "        )\n",
        "\n",
        "        # 5. Critical early engagement indicators\n",
        "        features_dict['day1_engaged'] = (features_dict['day_1_total'] > 0).astype(int)\n",
        "        features_dict['day2_engaged'] = (features_dict['day_2_total'] > 0).astype(int)\n",
        "        features_dict['day3_engaged'] = (features_dict['day_3_total'] > 0).astype(int)\n",
        "\n",
        "        features_dict['early_consistency'] = (\n",
        "            features_dict['day1_engaged'] +\n",
        "            features_dict['day2_engaged'] +\n",
        "            features_dict['day3_engaged']\n",
        "        )\n",
        "\n",
        "        # 6. Advanced behavioral patterns\n",
        "        features_dict['total_activity'] = daily_totals_df.sum(axis=1)\n",
        "        features_dict['active_days'] = (daily_totals_df > 0).sum(axis=1)\n",
        "        features_dict['activity_per_day'] = features_dict['total_activity'] / (features_dict['active_days'] + 1)\n",
        "\n",
        "        # Engagement decline patterns\n",
        "        features_dict['day1_to_day7_decline'] = (\n",
        "            features_dict['day_1_total'] - features_dict['day_7_total']\n",
        "        ).clip(lower=0)\n",
        "\n",
        "        # Sustained engagement\n",
        "        features_dict['sustained_week2'] = (daily_totals_df.iloc[:, 7:14] > 0).sum(axis=1)\n",
        "        features_dict['sustained_week3'] = (daily_totals_df.iloc[:, 14:21] > 0).sum(axis=1)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        features_df = pd.DataFrame(features_dict)\n",
        "\n",
        "        # 7. Interaction features for deep learning\n",
        "        # These help the neural network learn complex patterns\n",
        "        features_df['day2_week1_interaction'] = features_df['day2_engaged'] * features_df['week_1_total']\n",
        "        features_df['problem_video_ratio'] = (features_df['problem_total'] + 1) / (features_df['video_total'] + 1)\n",
        "        features_df['early_late_ratio'] = (features_df['week_1_total'] + 1) / (features_df['week_4_total'] + 1)\n",
        "\n",
        "        # 8. Statistical features\n",
        "        for col in ['day_1_total', 'day_2_total', 'day_3_total', 'week_1_total']:\n",
        "            if col in features_df.columns:\n",
        "                # Log transform for skewed distributions\n",
        "                features_df[f'{col}_log'] = np.log1p(features_df[col])\n",
        "                # Square root transform\n",
        "                features_df[f'{col}_sqrt'] = np.sqrt(features_df[col])\n",
        "\n",
        "        print(f\"‚úÖ Created {len(features_df.columns)} features for deep learning\")\n",
        "        return features_df\n",
        "\n",
        "    def prepare_data_for_dl(self, df, balance_data=True):\n",
        "        \"\"\"\n",
        "        Prepare data specifically for deep learning with proper preprocessing\n",
        "        \"\"\"\n",
        "        print(\"üìä Preparing data for deep learning...\")\n",
        "\n",
        "        # Engineer features\n",
        "        X = self.engineer_deep_features(df)\n",
        "        y = df['dropout'].values\n",
        "\n",
        "        # Handle missing values\n",
        "        X = X.fillna(0)\n",
        "\n",
        "        # Remove any infinite values\n",
        "        X = X.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = X.columns.tolist()\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale features (important for neural networks)\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # Handle class imbalance if requested\n",
        "        if balance_data:\n",
        "            print(\"‚öñÔ∏è Balancing dataset with SMOTE...\")\n",
        "            # Use SMOTE for oversampling minority class\n",
        "            smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "            X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        print(f\"üìà Training set: {len(X_train_scaled)} samples\")\n",
        "        print(f\"üìâ Test set: {len(X_test_scaled)} samples\")\n",
        "        print(f\"‚öñÔ∏è Training class distribution - Dropout: {np.sum(y_train)} ({np.mean(y_train)*100:.1f}%)\")\n",
        "\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "    def create_advanced_neural_network(self, input_dim):\n",
        "        \"\"\"\n",
        "        Create advanced neural network architecture optimized for dropout prediction\n",
        "        \"\"\"\n",
        "        print(\"üß† Creating advanced neural network architecture...\")\n",
        "\n",
        "        # Input layer\n",
        "        inputs = layers.Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "        # Feature preprocessing layers\n",
        "        x = layers.BatchNormalization(name='input_batch_norm')(inputs)\n",
        "        x = layers.Dropout(0.1, name='input_dropout')(x)\n",
        "\n",
        "        # First hidden block - Focus on early indicators\n",
        "        x = layers.Dense(256, activation='relu', name='dense_1')(x)\n",
        "        x = layers.BatchNormalization(name='batch_norm_1')(x)\n",
        "        x = layers.Dropout(0.3, name='dropout_1')(x)\n",
        "\n",
        "        # Second hidden block - Pattern recognition\n",
        "        x = layers.Dense(128, activation='relu', name='dense_2')(x)\n",
        "        x = layers.BatchNormalization(name='batch_norm_2')(x)\n",
        "        x = layers.Dropout(0.3, name='dropout_2')(x)\n",
        "\n",
        "        # Third hidden block - Complex interactions\n",
        "        x = layers.Dense(64, activation='relu', name='dense_3')(x)\n",
        "        x = layers.BatchNormalization(name='batch_norm_3')(x)\n",
        "        x = layers.Dropout(0.2, name='dropout_3')(x)\n",
        "\n",
        "        # Fourth hidden block - Final pattern synthesis\n",
        "        x = layers.Dense(32, activation='relu', name='dense_4')(x)\n",
        "        x = layers.BatchNormalization(name='batch_norm_4')(x)\n",
        "        x = layers.Dropout(0.2, name='dropout_4')(x)\n",
        "\n",
        "        # Output layer\n",
        "        outputs = layers.Dense(1, activation='sigmoid', name='output_layer')(x)\n",
        "\n",
        "        # Create model\n",
        "        model = keras.Model(inputs=inputs, outputs=outputs, name='dropout_predictor')\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_attention_network(self, input_dim):\n",
        "        \"\"\"\n",
        "        Create neural network with attention mechanism for temporal features\n",
        "        \"\"\"\n",
        "        print(\"üéØ Creating attention-based neural network...\")\n",
        "\n",
        "        inputs = layers.Input(shape=(input_dim,))\n",
        "\n",
        "        # Split features into temporal and static\n",
        "        # Assume first 30 features are daily totals, rest are aggregated\n",
        "        temporal_features = layers.Lambda(lambda x: x[:, :30])(inputs)\n",
        "        static_features = layers.Lambda(lambda x: x[:, 30:])(inputs)\n",
        "\n",
        "        # Process temporal features with attention\n",
        "        temporal_reshaped = layers.Reshape((30, 1))(temporal_features)\n",
        "\n",
        "        # LSTM for sequence processing\n",
        "        lstm_out = layers.LSTM(64, return_sequences=True)(temporal_reshaped)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attention = layers.Dense(1, activation='tanh')(lstm_out)\n",
        "        attention = layers.Flatten()(attention)\n",
        "        attention = layers.Activation('softmax')(attention)\n",
        "        attention = layers.RepeatVector(64)(attention)\n",
        "        attention = layers.Permute([2, 1])(attention)\n",
        "\n",
        "        # Apply attention\n",
        "        attended = layers.multiply([lstm_out, attention])\n",
        "        attended = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1))(attended)\n",
        "\n",
        "        # Process static features\n",
        "        static_processed = layers.Dense(128, activation='relu')(static_features)\n",
        "        static_processed = layers.Dropout(0.2)(static_processed)\n",
        "        static_processed = layers.Dense(64, activation='relu')(static_processed)\n",
        "\n",
        "        # Combine temporal and static features\n",
        "        combined = layers.concatenate([attended, static_processed])\n",
        "\n",
        "        # Final processing\n",
        "        x = layers.Dense(128, activation='relu')(combined)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "\n",
        "        x = layers.Dense(64, activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.2)(x)\n",
        "\n",
        "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = keras.Model(inputs=inputs, outputs=outputs, name='attention_dropout_predictor')\n",
        "        return model\n",
        "\n",
        "    def train_deep_ensemble(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Train ensemble of neural networks for maximum accuracy\n",
        "        \"\"\"\n",
        "        print(\"üöÄ Training deep learning ensemble...\")\n",
        "\n",
        "        input_dim = X_train.shape[1]\n",
        "        self.ensemble_models = []\n",
        "\n",
        "        # Model 1: Standard deep network\n",
        "        model1 = self.create_advanced_neural_network(input_dim)\n",
        "        model1.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', 'precision', 'recall']\n",
        "        )\n",
        "\n",
        "        # Model 2: Different architecture\n",
        "        model2 = keras.Sequential([\n",
        "            layers.Input(shape=(input_dim,)),\n",
        "            layers.Dense(512, activation='relu'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.4),\n",
        "            layers.Dense(256, activation='relu'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ], name='deep_network_2')\n",
        "\n",
        "        model2.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.0005),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', 'precision', 'recall']\n",
        "        )\n",
        "\n",
        "        # Model 3: Attention-based (if we have enough temporal features)\n",
        "        if input_dim >= 60:  # Need enough features for attention mechanism\n",
        "            model3 = self.create_attention_network(input_dim)\n",
        "            model3.compile(\n",
        "                optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', 'precision', 'recall']\n",
        "            )\n",
        "        else:\n",
        "            # Fallback to another standard architecture\n",
        "            model3 = keras.Sequential([\n",
        "                layers.Input(shape=(input_dim,)),\n",
        "                layers.Dense(256, activation='swish'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.Dropout(0.3),\n",
        "                layers.Dense(128, activation='swish'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.Dropout(0.2),\n",
        "                layers.Dense(64, activation='swish'),\n",
        "                layers.Dropout(0.2),\n",
        "                layers.Dense(1, activation='sigmoid')\n",
        "            ], name='swish_network')\n",
        "\n",
        "            model3.compile(\n",
        "                optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', 'precision', 'recall']\n",
        "            )\n",
        "\n",
        "        # Callbacks for training\n",
        "        callbacks_list = [\n",
        "            callbacks.EarlyStopping(\n",
        "                monitor='val_accuracy',\n",
        "                patience=15,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=8,\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            ),\n",
        "            callbacks.ModelCheckpoint(\n",
        "                'best_model_{epoch:02d}_{val_accuracy:.4f}.h5',\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train each model\n",
        "        models = [model1, model2, model3]\n",
        "        histories = []\n",
        "\n",
        "        for i, model in enumerate(models):\n",
        "            print(f\"\\nüî• Training Model {i+1}/3...\")\n",
        "\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=100,\n",
        "                batch_size=64,\n",
        "                callbacks=callbacks_list,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            histories.append(history)\n",
        "            self.ensemble_models.append(model)\n",
        "\n",
        "        self.history = histories\n",
        "        self.is_trained = True\n",
        "        print(\"‚úÖ Ensemble training completed!\")\n",
        "\n",
        "        return histories\n",
        "\n",
        "    def predict_ensemble(self, X_test):\n",
        "        \"\"\"\n",
        "        Make predictions using ensemble of models\n",
        "        \"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Models must be trained first!\")\n",
        "\n",
        "        # Get predictions from all models\n",
        "        predictions = []\n",
        "        probabilities = []\n",
        "\n",
        "        for i, model in enumerate(self.ensemble_models):\n",
        "            pred_proba = model.predict(X_test, verbose=0)\n",
        "            pred_binary = (pred_proba > 0.5).astype(int)\n",
        "\n",
        "            predictions.append(pred_binary.flatten())\n",
        "            probabilities.append(pred_proba.flatten())\n",
        "\n",
        "        # Ensemble methods\n",
        "        # Method 1: Average probabilities\n",
        "        avg_probabilities = np.mean(probabilities, axis=0)\n",
        "        avg_predictions = (avg_probabilities > 0.5).astype(int)\n",
        "\n",
        "        # Method 2: Majority voting\n",
        "        majority_predictions = np.round(np.mean(predictions, axis=0)).astype(int)\n",
        "\n",
        "        # Method 3: Weighted average (give more weight to better performing models)\n",
        "        # For simplicity, using equal weights here\n",
        "        ensemble_probabilities = avg_probabilities\n",
        "        ensemble_predictions = avg_predictions\n",
        "\n",
        "        return ensemble_predictions, ensemble_probabilities\n",
        "\n",
        "    def evaluate_deep_learning(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Comprehensive evaluation of deep learning models\n",
        "        \"\"\"\n",
        "        print(\"üìä Evaluating Deep Learning Models...\")\n",
        "\n",
        "        # Individual model performance\n",
        "        individual_results = {}\n",
        "\n",
        "        for i, model in enumerate(self.ensemble_models):\n",
        "            pred_proba = model.predict(X_test, verbose=0)\n",
        "            pred_binary = (pred_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "            accuracy = accuracy_score(y_test, pred_binary)\n",
        "            individual_results[f'model_{i+1}'] = {\n",
        "                'accuracy': accuracy,\n",
        "                'predictions': pred_binary,\n",
        "                'probabilities': pred_proba.flatten()\n",
        "            }\n",
        "\n",
        "            print(f\"Model {i+1} Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "        # Ensemble performance\n",
        "        ensemble_pred, ensemble_prob = self.predict_ensemble(X_test)\n",
        "\n",
        "        # Calculate comprehensive metrics\n",
        "        accuracy = accuracy_score(y_test, ensemble_pred)\n",
        "\n",
        "        # Confusion matrix\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, ensemble_pred).ravel()\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        balanced_accuracy = (recall + specificity) / 2\n",
        "\n",
        "        ensemble_results = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'specificity': specificity,\n",
        "            'f1_score': f1,\n",
        "            'balanced_accuracy': balanced_accuracy,\n",
        "            'confusion_matrix': {'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn}\n",
        "        }\n",
        "\n",
        "        return individual_results, ensemble_results\n",
        "\n",
        "    def train_and_evaluate(self, df):\n",
        "        \"\"\"\n",
        "        Complete deep learning pipeline\n",
        "        \"\"\"\n",
        "        print(\"üß† Starting Deep Learning Pipeline for Dropout Prediction...\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Prepare data\n",
        "        X_train, X_test, y_train, y_test = self.prepare_data_for_dl(df)\n",
        "\n",
        "        # Create validation split\n",
        "        X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "        )\n",
        "\n",
        "        # Train ensemble\n",
        "        histories = self.train_deep_ensemble(X_train_final, y_train_final, X_val, y_val)\n",
        "\n",
        "        # Evaluate models\n",
        "        individual_results, ensemble_results = self.evaluate_deep_learning(X_test, y_test)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nüèÜ DEEP LEARNING ENSEMBLE RESULTS:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"üéØ ACCURACY: {ensemble_results['accuracy']:.4f} ({ensemble_results['accuracy']*100:.2f}%)\")\n",
        "        print(f\"‚öñÔ∏è BALANCED ACCURACY: {ensemble_results['balanced_accuracy']:.4f} ({ensemble_results['balanced_accuracy']*100:.2f}%)\")\n",
        "        print(f\"üìä PRECISION: {ensemble_results['precision']:.4f} ({ensemble_results['precision']*100:.2f}%)\")\n",
        "        print(f\"üîç RECALL: {ensemble_results['recall']:.4f} ({ensemble_results['recall']*100:.2f}%)\")\n",
        "        print(f\"üõ°Ô∏è SPECIFICITY: {ensemble_results['specificity']:.4f} ({ensemble_results['specificity']*100:.2f}%)\")\n",
        "        print(f\"üìà F1-SCORE: {ensemble_results['f1_score']:.4f} ({ensemble_results['f1_score']*100:.2f}%)\")\n",
        "\n",
        "        cm = ensemble_results['confusion_matrix']\n",
        "        print(f\"\\nüìã Confusion Matrix:\")\n",
        "        print(f\"   Predicted:    Dropout  Complete\")\n",
        "        print(f\"   Actual Dropout:  {cm['tp']:>6}    {cm['fn']:>6}\")\n",
        "        print(f\"   Actual Complete: {cm['fp']:>6}    {cm['tn']:>6}\")\n",
        "\n",
        "        # Success evaluation\n",
        "        if ensemble_results['accuracy'] >= 0.90:\n",
        "            print(f\"\\nüéâüéâüéâ DEEP LEARNING SUCCESS! üéâüéâüéâ\")\n",
        "            print(f\"‚úÖ Achieved {ensemble_results['accuracy']*100:.2f}% accuracy!\")\n",
        "            print(f\"üß† Neural networks successfully learned complex dropout patterns!\")\n",
        "        else:\n",
        "            print(f\"\\nüöÄ EXCELLENT DEEP LEARNING PERFORMANCE!\")\n",
        "            print(f\"üìà Achieved {ensemble_results['accuracy']*100:.2f}% accuracy\")\n",
        "            print(f\"üéØ Very competitive results with traditional ML methods!\")\n",
        "\n",
        "        return {\n",
        "            'individual_results': individual_results,\n",
        "            'ensemble_results': ensemble_results,\n",
        "            'training_histories': histories,\n",
        "            'feature_names': self.feature_names\n",
        "        }\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"\n",
        "        Plot training history for all models\n",
        "        \"\"\"\n",
        "        if not self.history:\n",
        "            print(\"No training history available!\")\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        for i, history in enumerate(self.history):\n",
        "            # Accuracy plot\n",
        "            axes[0, 0].plot(history.history['accuracy'], label=f'Model {i+1} Train')\n",
        "            axes[0, 0].plot(history.history['val_accuracy'], label=f'Model {i+1} Val')\n",
        "\n",
        "        axes[0, 0].set_title('Model Accuracy')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Accuracy')\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        # Loss plot\n",
        "        for i, history in enumerate(self.history):\n",
        "            axes[0, 1].plot(history.history['loss'], label=f'Model {i+1} Train')\n",
        "            axes[0, 1].plot(history.history['val_loss'], label=f'Model {i+1} Val')\n",
        "\n",
        "        axes[0, 1].set_title('Model Loss')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Loss')\n",
        "        axes[0, 1].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Usage Example:\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the deep learning predictor\n",
        "    dl_predictor = DeepLearningDropoutPredictor()\n",
        "\n",
        "    # Load your data\n",
        "    df = pd.read_csv('model1_210_features.csv')\n",
        "\n",
        "    # Train and evaluate\n",
        "    results = dl_predictor.train_and_evaluate(df)\n",
        "\n",
        "    # Plot training history\n",
        "    dl_predictor.plot_training_history()\n",
        "\n",
        "    print(\"üß† Deep Learning Dropout Predictor Ready!\")\n",
        "    print(\"üìù Load your CSV file and call: results = dl_predictor.train_and_evaluate(df)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t4c2PDA3tt9I",
        "outputId": "c1ca3ec0-c664-4da0-a9af-c457eafcb80e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† Starting Deep Learning Pipeline for Dropout Prediction...\n",
            "======================================================================\n",
            "üìä Preparing data for deep learning...\n",
            "üß† Engineering features for deep learning...\n",
            "‚úÖ Created 97 features for deep learning\n",
            "‚öñÔ∏è Balancing dataset with SMOTE...\n",
            "üìà Training set: 152928 samples\n",
            "üìâ Test set: 24109 samples\n",
            "‚öñÔ∏è Training class distribution - Dropout: 76464 (50.0%)\n",
            "üöÄ Training deep learning ensemble...\n",
            "üß† Creating advanced neural network architecture...\n",
            "üéØ Creating attention-based neural network...\n",
            "\n",
            "üî• Training Model 1/3...\n",
            "Epoch 1/100\n",
            "\u001b[1m1907/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7614 - loss: 0.5187 - precision: 0.7416 - recall: 0.8023\n",
            "Epoch 1: val_accuracy improved from -inf to 0.78124, saving model to best_model_01_0.7812.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - accuracy: 0.7615 - loss: 0.5186 - precision: 0.7416 - recall: 0.8024 - val_accuracy: 0.7812 - val_loss: 0.4744 - val_precision: 0.7569 - val_recall: 0.8287 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7817 - loss: 0.4786 - precision: 0.7559 - recall: 0.8324\n",
            "Epoch 2: val_accuracy did not improve from 0.78124\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.7817 - loss: 0.4786 - precision: 0.7559 - recall: 0.8324 - val_accuracy: 0.7807 - val_loss: 0.4726 - val_precision: 0.7608 - val_recall: 0.8190 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m1907/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7822 - loss: 0.4763 - precision: 0.7560 - recall: 0.8336\n",
            "Epoch 3: val_accuracy improved from 0.78124 to 0.78291, saving model to best_model_03_0.7829.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7822 - loss: 0.4763 - precision: 0.7560 - recall: 0.8336 - val_accuracy: 0.7829 - val_loss: 0.4694 - val_precision: 0.7563 - val_recall: 0.8349 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7829 - loss: 0.4733 - precision: 0.7552 - recall: 0.8373\n",
            "Epoch 4: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7829 - loss: 0.4733 - precision: 0.7552 - recall: 0.8373 - val_accuracy: 0.7820 - val_loss: 0.4684 - val_precision: 0.7612 - val_recall: 0.8218 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7842 - loss: 0.4709 - precision: 0.7559 - recall: 0.8398\n",
            "Epoch 5: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7842 - loss: 0.4709 - precision: 0.7559 - recall: 0.8398 - val_accuracy: 0.7827 - val_loss: 0.4686 - val_precision: 0.7701 - val_recall: 0.8060 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m1906/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7847 - loss: 0.4703 - precision: 0.7552 - recall: 0.8427\n",
            "Epoch 6: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7847 - loss: 0.4703 - precision: 0.7552 - recall: 0.8428 - val_accuracy: 0.7800 - val_loss: 0.4698 - val_precision: 0.7715 - val_recall: 0.7957 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7863 - loss: 0.4686 - precision: 0.7573 - recall: 0.8427\n",
            "Epoch 7: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7863 - loss: 0.4686 - precision: 0.7573 - recall: 0.8427 - val_accuracy: 0.7811 - val_loss: 0.4678 - val_precision: 0.7762 - val_recall: 0.7900 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7863 - loss: 0.4661 - precision: 0.7573 - recall: 0.8428\n",
            "Epoch 8: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7863 - loss: 0.4661 - precision: 0.7573 - recall: 0.8428 - val_accuracy: 0.7800 - val_loss: 0.4687 - val_precision: 0.7767 - val_recall: 0.7859 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7873 - loss: 0.4640 - precision: 0.7572 - recall: 0.8459\n",
            "Epoch 9: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7873 - loss: 0.4640 - precision: 0.7572 - recall: 0.8459 - val_accuracy: 0.7775 - val_loss: 0.4747 - val_precision: 0.7790 - val_recall: 0.7748 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7888 - loss: 0.4639 - precision: 0.7576 - recall: 0.8496\n",
            "Epoch 10: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7888 - loss: 0.4639 - precision: 0.7576 - recall: 0.8496 - val_accuracy: 0.7758 - val_loss: 0.4735 - val_precision: 0.7821 - val_recall: 0.7646 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1907/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7894 - loss: 0.4619 - precision: 0.7574 - recall: 0.8518\n",
            "Epoch 11: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7894 - loss: 0.4619 - precision: 0.7574 - recall: 0.8518 - val_accuracy: 0.7761 - val_loss: 0.4722 - val_precision: 0.7794 - val_recall: 0.7703 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7892 - loss: 0.4617 - precision: 0.7572 - recall: 0.8516\n",
            "Epoch 12: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.4617 - precision: 0.7572 - recall: 0.8516 - val_accuracy: 0.7680 - val_loss: 0.4818 - val_precision: 0.7937 - val_recall: 0.7243 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7894 - loss: 0.4609 - precision: 0.7571 - recall: 0.8525\n",
            "Epoch 13: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7894 - loss: 0.4609 - precision: 0.7571 - recall: 0.8525 - val_accuracy: 0.7655 - val_loss: 0.4882 - val_precision: 0.7957 - val_recall: 0.7144 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1906/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7912 - loss: 0.4599 - precision: 0.7593 - recall: 0.8530\n",
            "Epoch 14: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7912 - loss: 0.4599 - precision: 0.7593 - recall: 0.8530 - val_accuracy: 0.7667 - val_loss: 0.4841 - val_precision: 0.7967 - val_recall: 0.7161 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7908 - loss: 0.4587 - precision: 0.7577 - recall: 0.8553\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7908 - loss: 0.4587 - precision: 0.7577 - recall: 0.8553 - val_accuracy: 0.7712 - val_loss: 0.4798 - val_precision: 0.7878 - val_recall: 0.7425 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m1906/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7927 - loss: 0.4567 - precision: 0.7581 - recall: 0.8597\n",
            "Epoch 16: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7927 - loss: 0.4566 - precision: 0.7581 - recall: 0.8597 - val_accuracy: 0.7678 - val_loss: 0.4891 - val_precision: 0.7977 - val_recall: 0.7176 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7933 - loss: 0.4551 - precision: 0.7589 - recall: 0.8598\n",
            "Epoch 17: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7933 - loss: 0.4551 - precision: 0.7589 - recall: 0.8598 - val_accuracy: 0.7666 - val_loss: 0.4896 - val_precision: 0.7973 - val_recall: 0.7150 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7936 - loss: 0.4543 - precision: 0.7597 - recall: 0.8591\n",
            "Epoch 18: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.7936 - loss: 0.4543 - precision: 0.7597 - recall: 0.8591 - val_accuracy: 0.7629 - val_loss: 0.4990 - val_precision: 0.7996 - val_recall: 0.7017 - learning_rate: 5.0000e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\n",
            "üî• Training Model 2/3...\n",
            "Epoch 1/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7632 - loss: 0.5175 - precision: 0.7373 - recall: 0.8182\n",
            "Epoch 1: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.7632 - loss: 0.5175 - precision: 0.7373 - recall: 0.8182 - val_accuracy: 0.7791 - val_loss: 0.4807 - val_precision: 0.7451 - val_recall: 0.8486 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.4812 - precision: 0.7568 - recall: 0.8289\n",
            "Epoch 2: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.4812 - precision: 0.7568 - recall: 0.8289 - val_accuracy: 0.7790 - val_loss: 0.4764 - val_precision: 0.7430 - val_recall: 0.8531 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7831 - loss: 0.4757 - precision: 0.7579 - recall: 0.8322\n",
            "Epoch 3: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7831 - loss: 0.4757 - precision: 0.7579 - recall: 0.8322 - val_accuracy: 0.7804 - val_loss: 0.4742 - val_precision: 0.7505 - val_recall: 0.8400 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7841 - loss: 0.4726 - precision: 0.7593 - recall: 0.8320\n",
            "Epoch 4: val_accuracy did not improve from 0.78291\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7841 - loss: 0.4726 - precision: 0.7593 - recall: 0.8320 - val_accuracy: 0.7821 - val_loss: 0.4730 - val_precision: 0.7479 - val_recall: 0.8508 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7853 - loss: 0.4707 - precision: 0.7590 - recall: 0.8364\n",
            "Epoch 5: val_accuracy improved from 0.78291 to 0.78425, saving model to best_model_05_0.7842.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7853 - loss: 0.4707 - precision: 0.7590 - recall: 0.8364 - val_accuracy: 0.7842 - val_loss: 0.4713 - val_precision: 0.7524 - val_recall: 0.8473 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7859 - loss: 0.4689 - precision: 0.7595 - recall: 0.8369\n",
            "Epoch 6: val_accuracy did not improve from 0.78425\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.7859 - loss: 0.4689 - precision: 0.7595 - recall: 0.8369 - val_accuracy: 0.7829 - val_loss: 0.4714 - val_precision: 0.7526 - val_recall: 0.8429 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7874 - loss: 0.4671 - precision: 0.7601 - recall: 0.8401\n",
            "Epoch 7: val_accuracy did not improve from 0.78425\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7874 - loss: 0.4671 - precision: 0.7601 - recall: 0.8401 - val_accuracy: 0.7837 - val_loss: 0.4698 - val_precision: 0.7474 - val_recall: 0.8571 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7890 - loss: 0.4654 - precision: 0.7597 - recall: 0.8456\n",
            "Epoch 8: val_accuracy improved from 0.78425 to 0.78539, saving model to best_model_08_0.7854.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.7890 - loss: 0.4654 - precision: 0.7597 - recall: 0.8456 - val_accuracy: 0.7854 - val_loss: 0.4679 - val_precision: 0.7533 - val_recall: 0.8487 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7890 - loss: 0.4639 - precision: 0.7608 - recall: 0.8432\n",
            "Epoch 9: val_accuracy improved from 0.78539 to 0.78634, saving model to best_model_09_0.7863.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.7890 - loss: 0.4639 - precision: 0.7608 - recall: 0.8432 - val_accuracy: 0.7863 - val_loss: 0.4678 - val_precision: 0.7568 - val_recall: 0.8439 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7909 - loss: 0.4622 - precision: 0.7624 - recall: 0.8455\n",
            "Epoch 10: val_accuracy did not improve from 0.78634\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7909 - loss: 0.4622 - precision: 0.7624 - recall: 0.8455 - val_accuracy: 0.7852 - val_loss: 0.4673 - val_precision: 0.7459 - val_recall: 0.8650 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7904 - loss: 0.4608 - precision: 0.7613 - recall: 0.8464\n",
            "Epoch 11: val_accuracy improved from 0.78634 to 0.78683, saving model to best_model_11_0.7868.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.7904 - loss: 0.4608 - precision: 0.7613 - recall: 0.8464 - val_accuracy: 0.7868 - val_loss: 0.4665 - val_precision: 0.7516 - val_recall: 0.8567 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7915 - loss: 0.4599 - precision: 0.7623 - recall: 0.8474\n",
            "Epoch 12: val_accuracy improved from 0.78683 to 0.78719, saving model to best_model_12_0.7872.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7915 - loss: 0.4599 - precision: 0.7623 - recall: 0.8474 - val_accuracy: 0.7872 - val_loss: 0.4659 - val_precision: 0.7534 - val_recall: 0.8539 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7931 - loss: 0.4591 - precision: 0.7634 - recall: 0.8496\n",
            "Epoch 13: val_accuracy improved from 0.78719 to 0.78765, saving model to best_model_13_0.7876.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7931 - loss: 0.4591 - precision: 0.7634 - recall: 0.8496 - val_accuracy: 0.7876 - val_loss: 0.4642 - val_precision: 0.7531 - val_recall: 0.8558 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7940 - loss: 0.4578 - precision: 0.7643 - recall: 0.8501\n",
            "Epoch 14: val_accuracy improved from 0.78765 to 0.78892, saving model to best_model_14_0.7889.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.7940 - loss: 0.4578 - precision: 0.7643 - recall: 0.8501 - val_accuracy: 0.7889 - val_loss: 0.4629 - val_precision: 0.7518 - val_recall: 0.8626 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7936 - loss: 0.4567 - precision: 0.7648 - recall: 0.8481\n",
            "Epoch 15: val_accuracy did not improve from 0.78892\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7936 - loss: 0.4567 - precision: 0.7648 - recall: 0.8481 - val_accuracy: 0.7876 - val_loss: 0.4638 - val_precision: 0.7492 - val_recall: 0.8646 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7952 - loss: 0.4550 - precision: 0.7661 - recall: 0.8501\n",
            "Epoch 16: val_accuracy improved from 0.78892 to 0.78918, saving model to best_model_16_0.7892.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7952 - loss: 0.4550 - precision: 0.7661 - recall: 0.8501 - val_accuracy: 0.7892 - val_loss: 0.4625 - val_precision: 0.7546 - val_recall: 0.8572 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7961 - loss: 0.4531 - precision: 0.7658 - recall: 0.8533\n",
            "Epoch 17: val_accuracy did not improve from 0.78918\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.7961 - loss: 0.4531 - precision: 0.7658 - recall: 0.8533 - val_accuracy: 0.7888 - val_loss: 0.4622 - val_precision: 0.7545 - val_recall: 0.8561 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7953 - loss: 0.4548 - precision: 0.7653 - recall: 0.8521\n",
            "Epoch 18: val_accuracy improved from 0.78918 to 0.79039, saving model to best_model_18_0.7904.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.7953 - loss: 0.4548 - precision: 0.7653 - recall: 0.8521 - val_accuracy: 0.7904 - val_loss: 0.4605 - val_precision: 0.7578 - val_recall: 0.8535 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7982 - loss: 0.4512 - precision: 0.7681 - recall: 0.8545\n",
            "Epoch 19: val_accuracy did not improve from 0.79039\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7982 - loss: 0.4512 - precision: 0.7681 - recall: 0.8545 - val_accuracy: 0.7898 - val_loss: 0.4594 - val_precision: 0.7598 - val_recall: 0.8474 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7974 - loss: 0.4513 - precision: 0.7666 - recall: 0.8552\n",
            "Epoch 20: val_accuracy improved from 0.79039 to 0.79389, saving model to best_model_20_0.7939.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.7974 - loss: 0.4513 - precision: 0.7666 - recall: 0.8552 - val_accuracy: 0.7939 - val_loss: 0.4580 - val_precision: 0.7529 - val_recall: 0.8749 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7991 - loss: 0.4475 - precision: 0.7678 - recall: 0.8576\n",
            "Epoch 21: val_accuracy did not improve from 0.79389\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.7991 - loss: 0.4475 - precision: 0.7678 - recall: 0.8576 - val_accuracy: 0.7928 - val_loss: 0.4581 - val_precision: 0.7530 - val_recall: 0.8714 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7990 - loss: 0.4481 - precision: 0.7668 - recall: 0.8593\n",
            "Epoch 22: val_accuracy did not improve from 0.79389\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 16ms/step - accuracy: 0.7990 - loss: 0.4481 - precision: 0.7668 - recall: 0.8593 - val_accuracy: 0.7939 - val_loss: 0.4574 - val_precision: 0.7551 - val_recall: 0.8700 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8002 - loss: 0.4467 - precision: 0.7701 - recall: 0.8562\n",
            "Epoch 23: val_accuracy did not improve from 0.79389\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.8002 - loss: 0.4467 - precision: 0.7701 - recall: 0.8562 - val_accuracy: 0.7930 - val_loss: 0.4565 - val_precision: 0.7531 - val_recall: 0.8719 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.4457 - precision: 0.7705 - recall: 0.8569\n",
            "Epoch 24: val_accuracy did not improve from 0.79389\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8007 - loss: 0.4457 - precision: 0.7705 - recall: 0.8569 - val_accuracy: 0.7937 - val_loss: 0.4560 - val_precision: 0.7542 - val_recall: 0.8714 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8013 - loss: 0.4448 - precision: 0.7706 - recall: 0.8581\n",
            "Epoch 25: val_accuracy improved from 0.79389 to 0.79474, saving model to best_model_25_0.7947.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8013 - loss: 0.4448 - precision: 0.7706 - recall: 0.8581 - val_accuracy: 0.7947 - val_loss: 0.4564 - val_precision: 0.7524 - val_recall: 0.8787 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8034 - loss: 0.4434 - precision: 0.7720 - recall: 0.8612\n",
            "Epoch 26: val_accuracy improved from 0.79474 to 0.79494, saving model to best_model_26_0.7949.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8034 - loss: 0.4434 - precision: 0.7720 - recall: 0.8613 - val_accuracy: 0.7949 - val_loss: 0.4540 - val_precision: 0.7593 - val_recall: 0.8637 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8030 - loss: 0.4419 - precision: 0.7712 - recall: 0.8616\n",
            "Epoch 27: val_accuracy improved from 0.79494 to 0.79628, saving model to best_model_27_0.7963.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8030 - loss: 0.4419 - precision: 0.7712 - recall: 0.8617 - val_accuracy: 0.7963 - val_loss: 0.4540 - val_precision: 0.7545 - val_recall: 0.8784 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8045 - loss: 0.4403 - precision: 0.7725 - recall: 0.8633\n",
            "Epoch 28: val_accuracy did not improve from 0.79628\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 16ms/step - accuracy: 0.8045 - loss: 0.4403 - precision: 0.7725 - recall: 0.8633 - val_accuracy: 0.7939 - val_loss: 0.4555 - val_precision: 0.7499 - val_recall: 0.8818 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8047 - loss: 0.4405 - precision: 0.7701 - recall: 0.8687\n",
            "Epoch 29: val_accuracy did not improve from 0.79628\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8047 - loss: 0.4405 - precision: 0.7701 - recall: 0.8687 - val_accuracy: 0.7959 - val_loss: 0.4519 - val_precision: 0.7567 - val_recall: 0.8721 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8076 - loss: 0.4360 - precision: 0.7732 - recall: 0.8706\n",
            "Epoch 30: val_accuracy improved from 0.79628 to 0.79684, saving model to best_model_30_0.7968.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8076 - loss: 0.4360 - precision: 0.7732 - recall: 0.8706 - val_accuracy: 0.7968 - val_loss: 0.4533 - val_precision: 0.7535 - val_recall: 0.8822 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8052 - loss: 0.4392 - precision: 0.7707 - recall: 0.8689\n",
            "Epoch 31: val_accuracy improved from 0.79684 to 0.79870, saving model to best_model_31_0.7987.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8052 - loss: 0.4392 - precision: 0.7707 - recall: 0.8689 - val_accuracy: 0.7987 - val_loss: 0.4502 - val_precision: 0.7604 - val_recall: 0.8722 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8078 - loss: 0.4360 - precision: 0.7748 - recall: 0.8679\n",
            "Epoch 32: val_accuracy did not improve from 0.79870\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8078 - loss: 0.4360 - precision: 0.7748 - recall: 0.8679 - val_accuracy: 0.7975 - val_loss: 0.4519 - val_precision: 0.7582 - val_recall: 0.8735 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8087 - loss: 0.4346 - precision: 0.7745 - recall: 0.8710\n",
            "Epoch 33: val_accuracy did not improve from 0.79870\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8087 - loss: 0.4346 - precision: 0.7745 - recall: 0.8710 - val_accuracy: 0.7986 - val_loss: 0.4511 - val_precision: 0.7551 - val_recall: 0.8840 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8082 - loss: 0.4337 - precision: 0.7734 - recall: 0.8721\n",
            "Epoch 34: val_accuracy did not improve from 0.79870\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8082 - loss: 0.4337 - precision: 0.7734 - recall: 0.8721 - val_accuracy: 0.7979 - val_loss: 0.4510 - val_precision: 0.7581 - val_recall: 0.8752 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8082 - loss: 0.4342 - precision: 0.7752 - recall: 0.8683\n",
            "Epoch 35: val_accuracy improved from 0.79870 to 0.79939, saving model to best_model_35_0.7994.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8082 - loss: 0.4342 - precision: 0.7752 - recall: 0.8683 - val_accuracy: 0.7994 - val_loss: 0.4518 - val_precision: 0.7582 - val_recall: 0.8792 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 0.4327 - precision: 0.7759 - recall: 0.8699\n",
            "Epoch 36: val_accuracy did not improve from 0.79939\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8093 - loss: 0.4327 - precision: 0.7759 - recall: 0.8699 - val_accuracy: 0.7986 - val_loss: 0.4517 - val_precision: 0.7552 - val_recall: 0.8837 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8108 - loss: 0.4301 - precision: 0.7762 - recall: 0.8736\n",
            "Epoch 37: val_accuracy improved from 0.79939 to 0.80030, saving model to best_model_37_0.8003.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8108 - loss: 0.4301 - precision: 0.7762 - recall: 0.8736 - val_accuracy: 0.8003 - val_loss: 0.4509 - val_precision: 0.7598 - val_recall: 0.8782 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8104 - loss: 0.4302 - precision: 0.7758 - recall: 0.8732\n",
            "Epoch 38: val_accuracy did not improve from 0.80030\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.8104 - loss: 0.4302 - precision: 0.7758 - recall: 0.8732 - val_accuracy: 0.7985 - val_loss: 0.4501 - val_precision: 0.7542 - val_recall: 0.8856 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8103 - loss: 0.4290 - precision: 0.7748 - recall: 0.8752\n",
            "Epoch 39: val_accuracy improved from 0.80030 to 0.80076, saving model to best_model_39_0.8008.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.8103 - loss: 0.4290 - precision: 0.7748 - recall: 0.8752 - val_accuracy: 0.8008 - val_loss: 0.4491 - val_precision: 0.7589 - val_recall: 0.8816 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8124 - loss: 0.4277 - precision: 0.7774 - recall: 0.8755\n",
            "Epoch 40: val_accuracy did not improve from 0.80076\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8124 - loss: 0.4277 - precision: 0.7774 - recall: 0.8755 - val_accuracy: 0.7993 - val_loss: 0.4495 - val_precision: 0.7566 - val_recall: 0.8824 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.4258 - precision: 0.7780 - recall: 0.8742\n",
            "Epoch 41: val_accuracy improved from 0.80076 to 0.80135, saving model to best_model_41_0.8013.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8123 - loss: 0.4258 - precision: 0.7780 - recall: 0.8742 - val_accuracy: 0.8013 - val_loss: 0.4481 - val_precision: 0.7645 - val_recall: 0.8709 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8140 - loss: 0.4271 - precision: 0.7788 - recall: 0.8772\n",
            "Epoch 42: val_accuracy did not improve from 0.80135\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8140 - loss: 0.4271 - precision: 0.7788 - recall: 0.8772 - val_accuracy: 0.7995 - val_loss: 0.4484 - val_precision: 0.7548 - val_recall: 0.8873 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8130 - loss: 0.4254 - precision: 0.7762 - recall: 0.8797\n",
            "Epoch 43: val_accuracy did not improve from 0.80135\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8130 - loss: 0.4254 - precision: 0.7762 - recall: 0.8797 - val_accuracy: 0.8005 - val_loss: 0.4476 - val_precision: 0.7579 - val_recall: 0.8829 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8143 - loss: 0.4250 - precision: 0.7779 - recall: 0.8800\n",
            "Epoch 44: val_accuracy did not improve from 0.80135\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.8143 - loss: 0.4250 - precision: 0.7779 - recall: 0.8800 - val_accuracy: 0.8009 - val_loss: 0.4469 - val_precision: 0.7620 - val_recall: 0.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8135 - loss: 0.4248 - precision: 0.7761 - recall: 0.8814\n",
            "Epoch 45: val_accuracy did not improve from 0.80135\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.8135 - loss: 0.4248 - precision: 0.7761 - recall: 0.8814 - val_accuracy: 0.8010 - val_loss: 0.4473 - val_precision: 0.7590 - val_recall: 0.8818 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.4229 - precision: 0.7804 - recall: 0.8778\n",
            "Epoch 46: val_accuracy did not improve from 0.80135\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8153 - loss: 0.4229 - precision: 0.7804 - recall: 0.8778 - val_accuracy: 0.8013 - val_loss: 0.4472 - val_precision: 0.7591 - val_recall: 0.8828 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.4211 - precision: 0.7785 - recall: 0.8792\n",
            "Epoch 47: val_accuracy improved from 0.80135 to 0.80311, saving model to best_model_47_0.8031.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8145 - loss: 0.4211 - precision: 0.7785 - recall: 0.8792 - val_accuracy: 0.8031 - val_loss: 0.4451 - val_precision: 0.7652 - val_recall: 0.8745 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8169 - loss: 0.4205 - precision: 0.7804 - recall: 0.8821\n",
            "Epoch 48: val_accuracy did not improve from 0.80311\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8169 - loss: 0.4205 - precision: 0.7804 - recall: 0.8821 - val_accuracy: 0.8028 - val_loss: 0.4458 - val_precision: 0.7595 - val_recall: 0.8863 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8159 - loss: 0.4195 - precision: 0.7787 - recall: 0.8830\n",
            "Epoch 49: val_accuracy did not improve from 0.80311\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.8159 - loss: 0.4195 - precision: 0.7786 - recall: 0.8830 - val_accuracy: 0.8010 - val_loss: 0.4464 - val_precision: 0.7562 - val_recall: 0.8885 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8164 - loss: 0.4190 - precision: 0.7787 - recall: 0.8842\n",
            "Epoch 50: val_accuracy did not improve from 0.80311\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.8165 - loss: 0.4190 - precision: 0.7787 - recall: 0.8842 - val_accuracy: 0.8029 - val_loss: 0.4464 - val_precision: 0.7574 - val_recall: 0.8913 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 0.4181 - precision: 0.7817 - recall: 0.8822\n",
            "Epoch 51: val_accuracy improved from 0.80311 to 0.80318, saving model to best_model_51_0.8032.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 0.4181 - precision: 0.7817 - recall: 0.8822 - val_accuracy: 0.8032 - val_loss: 0.4453 - val_precision: 0.7596 - val_recall: 0.8872 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.4191 - precision: 0.7801 - recall: 0.8824\n",
            "Epoch 52: val_accuracy improved from 0.80318 to 0.80413, saving model to best_model_52_0.8041.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8168 - loss: 0.4191 - precision: 0.7801 - recall: 0.8824 - val_accuracy: 0.8041 - val_loss: 0.4451 - val_precision: 0.7591 - val_recall: 0.8911 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 0.4168 - precision: 0.7797 - recall: 0.8860\n",
            "Epoch 53: val_accuracy did not improve from 0.80413\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 0.4168 - precision: 0.7797 - recall: 0.8860 - val_accuracy: 0.8020 - val_loss: 0.4454 - val_precision: 0.7571 - val_recall: 0.8894 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8197 - loss: 0.4158 - precision: 0.7826 - recall: 0.8854\n",
            "Epoch 54: val_accuracy improved from 0.80413 to 0.80445, saving model to best_model_54_0.8045.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8197 - loss: 0.4158 - precision: 0.7826 - recall: 0.8854 - val_accuracy: 0.8045 - val_loss: 0.4442 - val_precision: 0.7627 - val_recall: 0.8840 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8194 - loss: 0.4164 - precision: 0.7833 - recall: 0.8832\n",
            "Epoch 55: val_accuracy improved from 0.80445 to 0.80583, saving model to best_model_55_0.8058.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8194 - loss: 0.4164 - precision: 0.7833 - recall: 0.8832 - val_accuracy: 0.8058 - val_loss: 0.4436 - val_precision: 0.7587 - val_recall: 0.8968 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8185 - loss: 0.4150 - precision: 0.7807 - recall: 0.8860\n",
            "Epoch 56: val_accuracy did not improve from 0.80583\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8185 - loss: 0.4150 - precision: 0.7807 - recall: 0.8860 - val_accuracy: 0.8053 - val_loss: 0.4449 - val_precision: 0.7616 - val_recall: 0.8888 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8190 - loss: 0.4145 - precision: 0.7812 - recall: 0.8863\n",
            "Epoch 57: val_accuracy did not improve from 0.80583\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8190 - loss: 0.4145 - precision: 0.7812 - recall: 0.8863 - val_accuracy: 0.8049 - val_loss: 0.4442 - val_precision: 0.7646 - val_recall: 0.8811 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8199 - loss: 0.4130 - precision: 0.7836 - recall: 0.8840\n",
            "Epoch 58: val_accuracy did not improve from 0.80583\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8199 - loss: 0.4130 - precision: 0.7836 - recall: 0.8840 - val_accuracy: 0.8027 - val_loss: 0.4489 - val_precision: 0.7508 - val_recall: 0.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8212 - loss: 0.4118 - precision: 0.7821 - recall: 0.8906\n",
            "Epoch 59: val_accuracy did not improve from 0.80583\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8212 - loss: 0.4118 - precision: 0.7821 - recall: 0.8906 - val_accuracy: 0.8052 - val_loss: 0.4447 - val_precision: 0.7617 - val_recall: 0.8883 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8216 - loss: 0.4112 - precision: 0.7852 - recall: 0.8856\n",
            "Epoch 60: val_accuracy did not improve from 0.80583\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.8216 - loss: 0.4112 - precision: 0.7852 - recall: 0.8856 - val_accuracy: 0.8056 - val_loss: 0.4445 - val_precision: 0.7594 - val_recall: 0.8946 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8226 - loss: 0.4100 - precision: 0.7856 - recall: 0.8876\n",
            "Epoch 61: val_accuracy did not improve from 0.80583\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8226 - loss: 0.4100 - precision: 0.7856 - recall: 0.8876 - val_accuracy: 0.8023 - val_loss: 0.4465 - val_precision: 0.7498 - val_recall: 0.9074 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8219 - loss: 0.4109 - precision: 0.7836 - recall: 0.8896\n",
            "Epoch 62: val_accuracy improved from 0.80583 to 0.80655, saving model to best_model_62_0.8065.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8219 - loss: 0.4109 - precision: 0.7836 - recall: 0.8896 - val_accuracy: 0.8065 - val_loss: 0.4442 - val_precision: 0.7570 - val_recall: 0.9029 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8225 - loss: 0.4090 - precision: 0.7839 - recall: 0.8908\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.80655\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8225 - loss: 0.4090 - precision: 0.7839 - recall: 0.8908 - val_accuracy: 0.8044 - val_loss: 0.4452 - val_precision: 0.7544 - val_recall: 0.9026 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8249 - loss: 0.4063 - precision: 0.7871 - recall: 0.8908\n",
            "Epoch 64: val_accuracy did not improve from 0.80655\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.8249 - loss: 0.4063 - precision: 0.7871 - recall: 0.8908 - val_accuracy: 0.8051 - val_loss: 0.4454 - val_precision: 0.7534 - val_recall: 0.9071 - learning_rate: 2.5000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8270 - loss: 0.4010 - precision: 0.7876 - recall: 0.8956\n",
            "Epoch 65: val_accuracy did not improve from 0.80655\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8270 - loss: 0.4010 - precision: 0.7876 - recall: 0.8956 - val_accuracy: 0.8059 - val_loss: 0.4448 - val_precision: 0.7555 - val_recall: 0.9045 - learning_rate: 2.5000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8273 - loss: 0.3988 - precision: 0.7882 - recall: 0.8952\n",
            "Epoch 66: val_accuracy did not improve from 0.80655\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8273 - loss: 0.3988 - precision: 0.7882 - recall: 0.8952 - val_accuracy: 0.8056 - val_loss: 0.4470 - val_precision: 0.7531 - val_recall: 0.9092 - learning_rate: 2.5000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8270 - loss: 0.3976 - precision: 0.7881 - recall: 0.8945\n",
            "Epoch 67: val_accuracy did not improve from 0.80655\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8270 - loss: 0.3976 - precision: 0.7881 - recall: 0.8945 - val_accuracy: 0.8039 - val_loss: 0.4472 - val_precision: 0.7503 - val_recall: 0.9109 - learning_rate: 2.5000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8309 - loss: 0.3940 - precision: 0.7913 - recall: 0.8991\n",
            "Epoch 68: val_accuracy improved from 0.80655 to 0.80700, saving model to best_model_68_0.8070.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8309 - loss: 0.3940 - precision: 0.7913 - recall: 0.8991 - val_accuracy: 0.8070 - val_loss: 0.4444 - val_precision: 0.7539 - val_recall: 0.9117 - learning_rate: 2.5000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8298 - loss: 0.3954 - precision: 0.7909 - recall: 0.8969\n",
            "Epoch 69: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8298 - loss: 0.3954 - precision: 0.7909 - recall: 0.8969 - val_accuracy: 0.8066 - val_loss: 0.4425 - val_precision: 0.7564 - val_recall: 0.9045 - learning_rate: 2.5000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 0.3914 - precision: 0.7915 - recall: 0.9019\n",
            "Epoch 70: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8322 - loss: 0.3914 - precision: 0.7915 - recall: 0.9019 - val_accuracy: 0.8060 - val_loss: 0.4447 - val_precision: 0.7527 - val_recall: 0.9115 - learning_rate: 2.5000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8316 - loss: 0.3921 - precision: 0.7926 - recall: 0.8983\n",
            "Epoch 71: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8316 - loss: 0.3921 - precision: 0.7926 - recall: 0.8983 - val_accuracy: 0.8068 - val_loss: 0.4441 - val_precision: 0.7526 - val_recall: 0.9140 - learning_rate: 2.5000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8325 - loss: 0.3921 - precision: 0.7927 - recall: 0.9006\n",
            "Epoch 72: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8325 - loss: 0.3921 - precision: 0.7927 - recall: 0.9006 - val_accuracy: 0.8029 - val_loss: 0.4491 - val_precision: 0.7444 - val_recall: 0.9226 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8319 - loss: 0.3909 - precision: 0.7923 - recall: 0.8999\n",
            "Epoch 73: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8319 - loss: 0.3909 - precision: 0.7923 - recall: 0.8999 - val_accuracy: 0.8037 - val_loss: 0.4490 - val_precision: 0.7462 - val_recall: 0.9207 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8329 - loss: 0.3904 - precision: 0.7936 - recall: 0.8999\n",
            "Epoch 74: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8329 - loss: 0.3904 - precision: 0.7936 - recall: 0.8999 - val_accuracy: 0.7981 - val_loss: 0.4532 - val_precision: 0.7363 - val_recall: 0.9290 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8333 - loss: 0.3901 - precision: 0.7923 - recall: 0.9034\n",
            "Epoch 75: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.8333 - loss: 0.3901 - precision: 0.7923 - recall: 0.9034 - val_accuracy: 0.8067 - val_loss: 0.4449 - val_precision: 0.7516 - val_recall: 0.9162 - learning_rate: 2.5000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8335 - loss: 0.3882 - precision: 0.7935 - recall: 0.9016\n",
            "Epoch 76: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8335 - loss: 0.3882 - precision: 0.7935 - recall: 0.9016 - val_accuracy: 0.8055 - val_loss: 0.4472 - val_precision: 0.7479 - val_recall: 0.9215 - learning_rate: 2.5000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8321 - loss: 0.3884 - precision: 0.7920 - recall: 0.9010\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8321 - loss: 0.3884 - precision: 0.7920 - recall: 0.9010 - val_accuracy: 0.8036 - val_loss: 0.4481 - val_precision: 0.7444 - val_recall: 0.9247 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 0.3884 - precision: 0.7916 - recall: 0.9019\n",
            "Epoch 78: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8322 - loss: 0.3884 - precision: 0.7916 - recall: 0.9019 - val_accuracy: 0.8065 - val_loss: 0.4458 - val_precision: 0.7506 - val_recall: 0.9183 - learning_rate: 1.2500e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m1908/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8332 - loss: 0.3862 - precision: 0.7925 - recall: 0.9029\n",
            "Epoch 79: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.8332 - loss: 0.3862 - precision: 0.7925 - recall: 0.9029 - val_accuracy: 0.8058 - val_loss: 0.4453 - val_precision: 0.7496 - val_recall: 0.9184 - learning_rate: 1.2500e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8339 - loss: 0.3834 - precision: 0.7934 - recall: 0.9030\n",
            "Epoch 80: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.8339 - loss: 0.3834 - precision: 0.7934 - recall: 0.9030 - val_accuracy: 0.8026 - val_loss: 0.4484 - val_precision: 0.7436 - val_recall: 0.9236 - learning_rate: 1.2500e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m1909/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8373 - loss: 0.3813 - precision: 0.7970 - recall: 0.9054\n",
            "Epoch 81: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8373 - loss: 0.3813 - precision: 0.7970 - recall: 0.9054 - val_accuracy: 0.8018 - val_loss: 0.4489 - val_precision: 0.7420 - val_recall: 0.9253 - learning_rate: 1.2500e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8369 - loss: 0.3812 - precision: 0.7952 - recall: 0.9076\n",
            "Epoch 82: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.8369 - loss: 0.3812 - precision: 0.7952 - recall: 0.9076 - val_accuracy: 0.8006 - val_loss: 0.4511 - val_precision: 0.7404 - val_recall: 0.9260 - learning_rate: 1.2500e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8377 - loss: 0.3796 - precision: 0.7968 - recall: 0.9067\n",
            "Epoch 83: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.8377 - loss: 0.3796 - precision: 0.7968 - recall: 0.9067 - val_accuracy: 0.8017 - val_loss: 0.4502 - val_precision: 0.7416 - val_recall: 0.9261 - learning_rate: 1.2500e-04\n",
            "Epoch 83: early stopping\n",
            "Restoring model weights from the end of the best epoch: 68.\n",
            "\n",
            "üî• Training Model 3/3...\n",
            "Epoch 1/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7688 - loss: 0.5092 - precision: 0.7423 - recall: 0.8239\n",
            "Epoch 1: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.7688 - loss: 0.5091 - precision: 0.7423 - recall: 0.8239 - val_accuracy: 0.7734 - val_loss: 0.4778 - val_precision: 0.7192 - val_recall: 0.8970 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7860 - loss: 0.4675 - precision: 0.7528 - recall: 0.8518\n",
            "Epoch 2: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 38ms/step - accuracy: 0.7860 - loss: 0.4675 - precision: 0.7528 - recall: 0.8518 - val_accuracy: 0.7811 - val_loss: 0.4662 - val_precision: 0.7277 - val_recall: 0.8983 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7904 - loss: 0.4587 - precision: 0.7575 - recall: 0.8546\n",
            "Epoch 3: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.7904 - loss: 0.4587 - precision: 0.7575 - recall: 0.8546 - val_accuracy: 0.7861 - val_loss: 0.4601 - val_precision: 0.7316 - val_recall: 0.9040 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7923 - loss: 0.4542 - precision: 0.7580 - recall: 0.8590\n",
            "Epoch 4: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.7923 - loss: 0.4542 - precision: 0.7580 - recall: 0.8591 - val_accuracy: 0.7841 - val_loss: 0.4621 - val_precision: 0.7232 - val_recall: 0.9207 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7952 - loss: 0.4503 - precision: 0.7600 - recall: 0.8631\n",
            "Epoch 5: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 38ms/step - accuracy: 0.7952 - loss: 0.4503 - precision: 0.7600 - recall: 0.8631 - val_accuracy: 0.7925 - val_loss: 0.4497 - val_precision: 0.7356 - val_recall: 0.9134 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7982 - loss: 0.4452 - precision: 0.7615 - recall: 0.8685\n",
            "Epoch 6: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 38ms/step - accuracy: 0.7982 - loss: 0.4452 - precision: 0.7615 - recall: 0.8685 - val_accuracy: 0.7908 - val_loss: 0.4520 - val_precision: 0.7288 - val_recall: 0.9263 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7992 - loss: 0.4414 - precision: 0.7618 - recall: 0.8708\n",
            "Epoch 7: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 35ms/step - accuracy: 0.7992 - loss: 0.4414 - precision: 0.7618 - recall: 0.8708 - val_accuracy: 0.7974 - val_loss: 0.4428 - val_precision: 0.7412 - val_recall: 0.9139 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7999 - loss: 0.4384 - precision: 0.7620 - recall: 0.8722\n",
            "Epoch 8: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.7999 - loss: 0.4384 - precision: 0.7620 - recall: 0.8722 - val_accuracy: 0.7923 - val_loss: 0.4469 - val_precision: 0.7281 - val_recall: 0.9328 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8033 - loss: 0.4344 - precision: 0.7642 - recall: 0.8774\n",
            "Epoch 9: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 36ms/step - accuracy: 0.8033 - loss: 0.4344 - precision: 0.7642 - recall: 0.8774 - val_accuracy: 0.7990 - val_loss: 0.4342 - val_precision: 0.7430 - val_recall: 0.9140 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8039 - loss: 0.4323 - precision: 0.7647 - recall: 0.8779\n",
            "Epoch 10: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8039 - loss: 0.4323 - precision: 0.7647 - recall: 0.8779 - val_accuracy: 0.7981 - val_loss: 0.4381 - val_precision: 0.7363 - val_recall: 0.9291 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8066 - loss: 0.4289 - precision: 0.7676 - recall: 0.8795\n",
            "Epoch 11: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.8066 - loss: 0.4289 - precision: 0.7676 - recall: 0.8795 - val_accuracy: 0.8028 - val_loss: 0.4285 - val_precision: 0.7501 - val_recall: 0.9082 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8067 - loss: 0.4262 - precision: 0.7672 - recall: 0.8807\n",
            "Epoch 12: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 36ms/step - accuracy: 0.8067 - loss: 0.4262 - precision: 0.7672 - recall: 0.8807 - val_accuracy: 0.8061 - val_loss: 0.4251 - val_precision: 0.7609 - val_recall: 0.8928 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8082 - loss: 0.4226 - precision: 0.7693 - recall: 0.8805\n",
            "Epoch 13: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8082 - loss: 0.4226 - precision: 0.7693 - recall: 0.8805 - val_accuracy: 0.8041 - val_loss: 0.4281 - val_precision: 0.7524 - val_recall: 0.9067 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8092 - loss: 0.4223 - precision: 0.7691 - recall: 0.8838\n",
            "Epoch 14: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - accuracy: 0.8092 - loss: 0.4223 - precision: 0.7691 - recall: 0.8838 - val_accuracy: 0.8059 - val_loss: 0.4254 - val_precision: 0.7518 - val_recall: 0.9133 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8095 - loss: 0.4203 - precision: 0.7708 - recall: 0.8811\n",
            "Epoch 15: val_accuracy did not improve from 0.80700\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 39ms/step - accuracy: 0.8095 - loss: 0.4203 - precision: 0.7708 - recall: 0.8811 - val_accuracy: 0.8021 - val_loss: 0.4287 - val_precision: 0.7407 - val_recall: 0.9297 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8116 - loss: 0.4183 - precision: 0.7709 - recall: 0.8869\n",
            "Epoch 16: val_accuracy improved from 0.80700 to 0.80726, saving model to best_model_16_0.8073.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8116 - loss: 0.4183 - precision: 0.7709 - recall: 0.8869 - val_accuracy: 0.8073 - val_loss: 0.4212 - val_precision: 0.7553 - val_recall: 0.9090 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8120 - loss: 0.4157 - precision: 0.7712 - recall: 0.8872\n",
            "Epoch 17: val_accuracy did not improve from 0.80726\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - accuracy: 0.8120 - loss: 0.4157 - precision: 0.7712 - recall: 0.8872 - val_accuracy: 0.8039 - val_loss: 0.4255 - val_precision: 0.7430 - val_recall: 0.9292 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8135 - loss: 0.4137 - precision: 0.7731 - recall: 0.8876\n",
            "Epoch 18: val_accuracy improved from 0.80726 to 0.80926, saving model to best_model_18_0.8093.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 39ms/step - accuracy: 0.8135 - loss: 0.4137 - precision: 0.7731 - recall: 0.8876 - val_accuracy: 0.8093 - val_loss: 0.4200 - val_precision: 0.7550 - val_recall: 0.9157 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8136 - loss: 0.4126 - precision: 0.7737 - recall: 0.8866\n",
            "Epoch 19: val_accuracy did not improve from 0.80926\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 38ms/step - accuracy: 0.8136 - loss: 0.4126 - precision: 0.7737 - recall: 0.8866 - val_accuracy: 0.8058 - val_loss: 0.4234 - val_precision: 0.7462 - val_recall: 0.9267 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8164 - loss: 0.4097 - precision: 0.7760 - recall: 0.8897\n",
            "Epoch 20: val_accuracy improved from 0.80926 to 0.81014, saving model to best_model_20_0.8101.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 37ms/step - accuracy: 0.8164 - loss: 0.4097 - precision: 0.7760 - recall: 0.8897 - val_accuracy: 0.8101 - val_loss: 0.4166 - val_precision: 0.7671 - val_recall: 0.8908 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8144 - loss: 0.4087 - precision: 0.7741 - recall: 0.8879\n",
            "Epoch 21: val_accuracy improved from 0.81014 to 0.81070, saving model to best_model_21_0.8107.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 35ms/step - accuracy: 0.8144 - loss: 0.4087 - precision: 0.7741 - recall: 0.8879 - val_accuracy: 0.8107 - val_loss: 0.4183 - val_precision: 0.7558 - val_recall: 0.9179 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8160 - loss: 0.4088 - precision: 0.7749 - recall: 0.8907\n",
            "Epoch 22: val_accuracy improved from 0.81070 to 0.81364, saving model to best_model_22_0.8136.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 35ms/step - accuracy: 0.8160 - loss: 0.4088 - precision: 0.7749 - recall: 0.8907 - val_accuracy: 0.8136 - val_loss: 0.4158 - val_precision: 0.7638 - val_recall: 0.9081 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8181 - loss: 0.4062 - precision: 0.7779 - recall: 0.8907\n",
            "Epoch 23: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 35ms/step - accuracy: 0.8181 - loss: 0.4062 - precision: 0.7779 - recall: 0.8907 - val_accuracy: 0.8112 - val_loss: 0.4191 - val_precision: 0.7524 - val_recall: 0.9277 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8184 - loss: 0.4055 - precision: 0.7780 - recall: 0.8913\n",
            "Epoch 24: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 38ms/step - accuracy: 0.8184 - loss: 0.4055 - precision: 0.7780 - recall: 0.8913 - val_accuracy: 0.8120 - val_loss: 0.4171 - val_precision: 0.7593 - val_recall: 0.9136 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8184 - loss: 0.4045 - precision: 0.7778 - recall: 0.8915\n",
            "Epoch 25: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 36ms/step - accuracy: 0.8184 - loss: 0.4045 - precision: 0.7778 - recall: 0.8915 - val_accuracy: 0.8110 - val_loss: 0.4159 - val_precision: 0.7597 - val_recall: 0.9099 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8198 - loss: 0.4019 - precision: 0.7794 - recall: 0.8921\n",
            "Epoch 26: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8198 - loss: 0.4019 - precision: 0.7794 - recall: 0.8921 - val_accuracy: 0.8127 - val_loss: 0.4153 - val_precision: 0.7637 - val_recall: 0.9056 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8199 - loss: 0.4015 - precision: 0.7782 - recall: 0.8949\n",
            "Epoch 27: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.8199 - loss: 0.4015 - precision: 0.7782 - recall: 0.8949 - val_accuracy: 0.8132 - val_loss: 0.4149 - val_precision: 0.7677 - val_recall: 0.8984 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8202 - loss: 0.3995 - precision: 0.7793 - recall: 0.8936\n",
            "Epoch 28: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 36ms/step - accuracy: 0.8202 - loss: 0.3995 - precision: 0.7793 - recall: 0.8936 - val_accuracy: 0.8115 - val_loss: 0.4165 - val_precision: 0.7608 - val_recall: 0.9088 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8228 - loss: 0.3978 - precision: 0.7812 - recall: 0.8969\n",
            "Epoch 29: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.8228 - loss: 0.3978 - precision: 0.7812 - recall: 0.8969 - val_accuracy: 0.8133 - val_loss: 0.4140 - val_precision: 0.7653 - val_recall: 0.9039 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8237 - loss: 0.3970 - precision: 0.7821 - recall: 0.8975\n",
            "Epoch 30: val_accuracy did not improve from 0.81364\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8237 - loss: 0.3970 - precision: 0.7821 - recall: 0.8975 - val_accuracy: 0.8129 - val_loss: 0.4160 - val_precision: 0.7664 - val_recall: 0.9002 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8236 - loss: 0.3956 - precision: 0.7821 - recall: 0.8973\n",
            "Epoch 31: val_accuracy improved from 0.81364 to 0.81452, saving model to best_model_31_0.8145.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.8236 - loss: 0.3956 - precision: 0.7821 - recall: 0.8973 - val_accuracy: 0.8145 - val_loss: 0.4151 - val_precision: 0.7657 - val_recall: 0.9064 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8250 - loss: 0.3935 - precision: 0.7837 - recall: 0.8979\n",
            "Epoch 32: val_accuracy did not improve from 0.81452\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 35ms/step - accuracy: 0.8250 - loss: 0.3935 - precision: 0.7837 - recall: 0.8979 - val_accuracy: 0.8135 - val_loss: 0.4149 - val_precision: 0.7621 - val_recall: 0.9114 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8256 - loss: 0.3916 - precision: 0.7837 - recall: 0.8997\n",
            "Epoch 33: val_accuracy did not improve from 0.81452\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 36ms/step - accuracy: 0.8256 - loss: 0.3916 - precision: 0.7837 - recall: 0.8997 - val_accuracy: 0.8128 - val_loss: 0.4145 - val_precision: 0.7632 - val_recall: 0.9070 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8258 - loss: 0.3916 - precision: 0.7842 - recall: 0.8990\n",
            "Epoch 34: val_accuracy improved from 0.81452 to 0.81505, saving model to best_model_34_0.8150.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8258 - loss: 0.3916 - precision: 0.7842 - recall: 0.8990 - val_accuracy: 0.8150 - val_loss: 0.4140 - val_precision: 0.7672 - val_recall: 0.9047 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8277 - loss: 0.3897 - precision: 0.7855 - recall: 0.9017\n",
            "Epoch 35: val_accuracy improved from 0.81505 to 0.81603, saving model to best_model_35_0.8160.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.8277 - loss: 0.3897 - precision: 0.7855 - recall: 0.9017 - val_accuracy: 0.8160 - val_loss: 0.4134 - val_precision: 0.7730 - val_recall: 0.8949 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8283 - loss: 0.3876 - precision: 0.7856 - recall: 0.9030\n",
            "Epoch 36: val_accuracy did not improve from 0.81603\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 35ms/step - accuracy: 0.8283 - loss: 0.3876 - precision: 0.7856 - recall: 0.9030 - val_accuracy: 0.8160 - val_loss: 0.4157 - val_precision: 0.7682 - val_recall: 0.9050 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8288 - loss: 0.3872 - precision: 0.7866 - recall: 0.9024\n",
            "Epoch 37: val_accuracy did not improve from 0.81603\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 37ms/step - accuracy: 0.8288 - loss: 0.3872 - precision: 0.7866 - recall: 0.9024 - val_accuracy: 0.8150 - val_loss: 0.4132 - val_precision: 0.7713 - val_recall: 0.8956 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8285 - loss: 0.3861 - precision: 0.7856 - recall: 0.9037\n",
            "Epoch 38: val_accuracy did not improve from 0.81603\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 36ms/step - accuracy: 0.8285 - loss: 0.3861 - precision: 0.7856 - recall: 0.9037 - val_accuracy: 0.8154 - val_loss: 0.4127 - val_precision: 0.7657 - val_recall: 0.9088 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8303 - loss: 0.3844 - precision: 0.7873 - recall: 0.9052\n",
            "Epoch 39: val_accuracy did not improve from 0.81603\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 36ms/step - accuracy: 0.8303 - loss: 0.3844 - precision: 0.7873 - recall: 0.9052 - val_accuracy: 0.8146 - val_loss: 0.4167 - val_precision: 0.7640 - val_recall: 0.9105 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8303 - loss: 0.3830 - precision: 0.7867 - recall: 0.9064\n",
            "Epoch 40: val_accuracy improved from 0.81603 to 0.81684, saving model to best_model_40_0.8168.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 38ms/step - accuracy: 0.8303 - loss: 0.3829 - precision: 0.7867 - recall: 0.9064 - val_accuracy: 0.8168 - val_loss: 0.4151 - val_precision: 0.7697 - val_recall: 0.9042 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8331 - loss: 0.3802 - precision: 0.7901 - recall: 0.9074\n",
            "Epoch 41: val_accuracy did not improve from 0.81684\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 37ms/step - accuracy: 0.8331 - loss: 0.3802 - precision: 0.7901 - recall: 0.9074 - val_accuracy: 0.8145 - val_loss: 0.4178 - val_precision: 0.7722 - val_recall: 0.8921 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8335 - loss: 0.3801 - precision: 0.7900 - recall: 0.9087\n",
            "Epoch 42: val_accuracy did not improve from 0.81684\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.8335 - loss: 0.3801 - precision: 0.7900 - recall: 0.9087 - val_accuracy: 0.8138 - val_loss: 0.4155 - val_precision: 0.7578 - val_recall: 0.9224 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8336 - loss: 0.3787 - precision: 0.7905 - recall: 0.9079\n",
            "Epoch 43: val_accuracy improved from 0.81684 to 0.81698, saving model to best_model_43_0.8170.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 35ms/step - accuracy: 0.8336 - loss: 0.3787 - precision: 0.7905 - recall: 0.9079 - val_accuracy: 0.8170 - val_loss: 0.4174 - val_precision: 0.7669 - val_recall: 0.9109 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8345 - loss: 0.3766 - precision: 0.7914 - recall: 0.9085\n",
            "Epoch 44: val_accuracy did not improve from 0.81698\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 37ms/step - accuracy: 0.8345 - loss: 0.3766 - precision: 0.7914 - recall: 0.9085 - val_accuracy: 0.8163 - val_loss: 0.4171 - val_precision: 0.7693 - val_recall: 0.9034 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8350 - loss: 0.3767 - precision: 0.7921 - recall: 0.9086\n",
            "Epoch 45: val_accuracy improved from 0.81698 to 0.81802, saving model to best_model_45_0.8180.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 38ms/step - accuracy: 0.8350 - loss: 0.3767 - precision: 0.7921 - recall: 0.9086 - val_accuracy: 0.8180 - val_loss: 0.4168 - val_precision: 0.7720 - val_recall: 0.9026 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8364 - loss: 0.3759 - precision: 0.7935 - recall: 0.9096\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.81802\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 38ms/step - accuracy: 0.8364 - loss: 0.3759 - precision: 0.7935 - recall: 0.9096 - val_accuracy: 0.8174 - val_loss: 0.4184 - val_precision: 0.7687 - val_recall: 0.9081 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8396 - loss: 0.3676 - precision: 0.7959 - recall: 0.9135\n",
            "Epoch 47: val_accuracy improved from 0.81802 to 0.81979, saving model to best_model_47_0.8198.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 35ms/step - accuracy: 0.8396 - loss: 0.3676 - precision: 0.7959 - recall: 0.9135 - val_accuracy: 0.8198 - val_loss: 0.4152 - val_precision: 0.7731 - val_recall: 0.9052 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8431 - loss: 0.3622 - precision: 0.8003 - recall: 0.9144\n",
            "Epoch 48: val_accuracy did not improve from 0.81979\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8431 - loss: 0.3622 - precision: 0.8003 - recall: 0.9144 - val_accuracy: 0.8195 - val_loss: 0.4177 - val_precision: 0.7754 - val_recall: 0.8994 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8450 - loss: 0.3596 - precision: 0.8010 - recall: 0.9182\n",
            "Epoch 49: val_accuracy did not improve from 0.81979\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.8450 - loss: 0.3596 - precision: 0.8010 - recall: 0.9182 - val_accuracy: 0.8190 - val_loss: 0.4160 - val_precision: 0.7703 - val_recall: 0.9092 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8453 - loss: 0.3587 - precision: 0.8017 - recall: 0.9177\n",
            "Epoch 50: val_accuracy did not improve from 0.81979\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 39ms/step - accuracy: 0.8453 - loss: 0.3587 - precision: 0.8017 - recall: 0.9177 - val_accuracy: 0.8188 - val_loss: 0.4153 - val_precision: 0.7700 - val_recall: 0.9092 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8453 - loss: 0.3578 - precision: 0.8017 - recall: 0.9178\n",
            "Epoch 51: val_accuracy improved from 0.81979 to 0.82028, saving model to best_model_51_0.8203.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 38ms/step - accuracy: 0.8453 - loss: 0.3578 - precision: 0.8017 - recall: 0.9178 - val_accuracy: 0.8203 - val_loss: 0.4206 - val_precision: 0.7727 - val_recall: 0.9075 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8456 - loss: 0.3567 - precision: 0.8018 - recall: 0.9183\n",
            "Epoch 52: val_accuracy improved from 0.82028 to 0.82080, saving model to best_model_52_0.8208.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8456 - loss: 0.3567 - precision: 0.8018 - recall: 0.9183 - val_accuracy: 0.8208 - val_loss: 0.4223 - val_precision: 0.7744 - val_recall: 0.9054 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8459 - loss: 0.3546 - precision: 0.8020 - recall: 0.9187\n",
            "Epoch 53: val_accuracy did not improve from 0.82080\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 38ms/step - accuracy: 0.8459 - loss: 0.3546 - precision: 0.8020 - recall: 0.9187 - val_accuracy: 0.8202 - val_loss: 0.4193 - val_precision: 0.7766 - val_recall: 0.8990 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8479 - loss: 0.3538 - precision: 0.8046 - recall: 0.9191\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.82080\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 38ms/step - accuracy: 0.8479 - loss: 0.3538 - precision: 0.8046 - recall: 0.9191 - val_accuracy: 0.8196 - val_loss: 0.4203 - val_precision: 0.7746 - val_recall: 0.9015 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8491 - loss: 0.3506 - precision: 0.8050 - recall: 0.9214\n",
            "Epoch 55: val_accuracy did not improve from 0.82080\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8491 - loss: 0.3506 - precision: 0.8050 - recall: 0.9214 - val_accuracy: 0.8194 - val_loss: 0.4205 - val_precision: 0.7739 - val_recall: 0.9024 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8513 - loss: 0.3477 - precision: 0.8071 - recall: 0.9235\n",
            "Epoch 56: val_accuracy improved from 0.82080 to 0.82119, saving model to best_model_56_0.8212.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 38ms/step - accuracy: 0.8513 - loss: 0.3477 - precision: 0.8071 - recall: 0.9235 - val_accuracy: 0.8212 - val_loss: 0.4198 - val_precision: 0.7785 - val_recall: 0.8979 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8517 - loss: 0.3460 - precision: 0.8088 - recall: 0.9213\n",
            "Epoch 57: val_accuracy did not improve from 0.82119\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 38ms/step - accuracy: 0.8517 - loss: 0.3460 - precision: 0.8088 - recall: 0.9213 - val_accuracy: 0.8200 - val_loss: 0.4208 - val_precision: 0.7749 - val_recall: 0.9022 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8533 - loss: 0.3444 - precision: 0.8090 - recall: 0.9249\n",
            "Epoch 58: val_accuracy improved from 0.82119 to 0.82240, saving model to best_model_58_0.8224.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 37ms/step - accuracy: 0.8533 - loss: 0.3444 - precision: 0.8090 - recall: 0.9249 - val_accuracy: 0.8224 - val_loss: 0.4214 - val_precision: 0.7761 - val_recall: 0.9063 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8547 - loss: 0.3425 - precision: 0.8114 - recall: 0.9243\n",
            "Epoch 59: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - accuracy: 0.8547 - loss: 0.3425 - precision: 0.8114 - recall: 0.9243 - val_accuracy: 0.8206 - val_loss: 0.4231 - val_precision: 0.7781 - val_recall: 0.8969 - learning_rate: 2.5000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8529 - loss: 0.3415 - precision: 0.8093 - recall: 0.9235\n",
            "Epoch 60: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 36ms/step - accuracy: 0.8529 - loss: 0.3415 - precision: 0.8093 - recall: 0.9235 - val_accuracy: 0.8210 - val_loss: 0.4230 - val_precision: 0.7762 - val_recall: 0.9020 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8526 - loss: 0.3430 - precision: 0.8086 - recall: 0.9240\n",
            "Epoch 61: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 37ms/step - accuracy: 0.8526 - loss: 0.3430 - precision: 0.8087 - recall: 0.9240 - val_accuracy: 0.8202 - val_loss: 0.4247 - val_precision: 0.7758 - val_recall: 0.9008 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8549 - loss: 0.3416 - precision: 0.8113 - recall: 0.9250\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 31ms/step - accuracy: 0.8549 - loss: 0.3416 - precision: 0.8113 - recall: 0.9250 - val_accuracy: 0.8213 - val_loss: 0.4247 - val_precision: 0.7781 - val_recall: 0.8988 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8560 - loss: 0.3400 - precision: 0.8122 - recall: 0.9263\n",
            "Epoch 63: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 33ms/step - accuracy: 0.8560 - loss: 0.3400 - precision: 0.8122 - recall: 0.9263 - val_accuracy: 0.8198 - val_loss: 0.4211 - val_precision: 0.7751 - val_recall: 0.9011 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8555 - loss: 0.3399 - precision: 0.8121 - recall: 0.9250\n",
            "Epoch 64: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 33ms/step - accuracy: 0.8555 - loss: 0.3399 - precision: 0.8121 - recall: 0.9250 - val_accuracy: 0.8210 - val_loss: 0.4227 - val_precision: 0.7764 - val_recall: 0.9017 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8582 - loss: 0.3383 - precision: 0.8150 - recall: 0.9270\n",
            "Epoch 65: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 31ms/step - accuracy: 0.8582 - loss: 0.3383 - precision: 0.8150 - recall: 0.9270 - val_accuracy: 0.8209 - val_loss: 0.4231 - val_precision: 0.7765 - val_recall: 0.9013 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8594 - loss: 0.3353 - precision: 0.8164 - recall: 0.9275\n",
            "Epoch 66: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8594 - loss: 0.3353 - precision: 0.8164 - recall: 0.9275 - val_accuracy: 0.8212 - val_loss: 0.4232 - val_precision: 0.7785 - val_recall: 0.8980 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8575 - loss: 0.3357 - precision: 0.8138 - recall: 0.9273\n",
            "Epoch 67: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 30ms/step - accuracy: 0.8575 - loss: 0.3357 - precision: 0.8138 - recall: 0.9273 - val_accuracy: 0.8218 - val_loss: 0.4250 - val_precision: 0.7791 - val_recall: 0.8984 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8584 - loss: 0.3360 - precision: 0.8147 - recall: 0.9281\n",
            "Epoch 68: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8584 - loss: 0.3360 - precision: 0.8147 - recall: 0.9281 - val_accuracy: 0.8217 - val_loss: 0.4245 - val_precision: 0.7775 - val_recall: 0.9015 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8585 - loss: 0.3339 - precision: 0.8147 - recall: 0.9281\n",
            "Epoch 69: val_accuracy did not improve from 0.82240\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 31ms/step - accuracy: 0.8585 - loss: 0.3339 - precision: 0.8147 - recall: 0.9281 - val_accuracy: 0.8213 - val_loss: 0.4239 - val_precision: 0.7785 - val_recall: 0.8982 - learning_rate: 1.2500e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8595 - loss: 0.3342 - precision: 0.8153 - recall: 0.9295\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 70: val_accuracy improved from 0.82240 to 0.82253, saving model to best_model_70_0.8225.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.8595 - loss: 0.3342 - precision: 0.8153 - recall: 0.9295 - val_accuracy: 0.8225 - val_loss: 0.4274 - val_precision: 0.7801 - val_recall: 0.8983 - learning_rate: 1.2500e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8582 - loss: 0.3349 - precision: 0.8150 - recall: 0.9269\n",
            "Epoch 71: val_accuracy improved from 0.82253 to 0.82289, saving model to best_model_71_0.8229.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 33ms/step - accuracy: 0.8582 - loss: 0.3349 - precision: 0.8150 - recall: 0.9269 - val_accuracy: 0.8229 - val_loss: 0.4260 - val_precision: 0.7797 - val_recall: 0.9001 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8595 - loss: 0.3328 - precision: 0.8164 - recall: 0.9278\n",
            "Epoch 72: val_accuracy did not improve from 0.82289\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8596 - loss: 0.3328 - precision: 0.8164 - recall: 0.9278 - val_accuracy: 0.8226 - val_loss: 0.4255 - val_precision: 0.7807 - val_recall: 0.8973 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8600 - loss: 0.3335 - precision: 0.8165 - recall: 0.9290\n",
            "Epoch 73: val_accuracy did not improve from 0.82289\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.8601 - loss: 0.3335 - precision: 0.8165 - recall: 0.9290 - val_accuracy: 0.8222 - val_loss: 0.4239 - val_precision: 0.7783 - val_recall: 0.9011 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8599 - loss: 0.3327 - precision: 0.8161 - recall: 0.9293\n",
            "Epoch 74: val_accuracy did not improve from 0.82289\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8599 - loss: 0.3327 - precision: 0.8161 - recall: 0.9293 - val_accuracy: 0.8215 - val_loss: 0.4257 - val_precision: 0.7793 - val_recall: 0.8971 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8597 - loss: 0.3307 - precision: 0.8158 - recall: 0.9294\n",
            "Epoch 75: val_accuracy did not improve from 0.82289\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 33ms/step - accuracy: 0.8598 - loss: 0.3307 - precision: 0.8158 - recall: 0.9294 - val_accuracy: 0.8227 - val_loss: 0.4259 - val_precision: 0.7811 - val_recall: 0.8968 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8598 - loss: 0.3318 - precision: 0.8159 - recall: 0.9295\n",
            "Epoch 76: val_accuracy improved from 0.82289 to 0.82293, saving model to best_model_76_0.8229.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.8598 - loss: 0.3318 - precision: 0.8159 - recall: 0.9295 - val_accuracy: 0.8229 - val_loss: 0.4263 - val_precision: 0.7808 - val_recall: 0.8979 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8597 - loss: 0.3314 - precision: 0.8154 - recall: 0.9299\n",
            "Epoch 77: val_accuracy did not improve from 0.82293\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8597 - loss: 0.3314 - precision: 0.8154 - recall: 0.9299 - val_accuracy: 0.8229 - val_loss: 0.4257 - val_precision: 0.7787 - val_recall: 0.9022 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8608 - loss: 0.3300 - precision: 0.8165 - recall: 0.9310\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.82293\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 30ms/step - accuracy: 0.8608 - loss: 0.3300 - precision: 0.8165 - recall: 0.9310 - val_accuracy: 0.8222 - val_loss: 0.4264 - val_precision: 0.7790 - val_recall: 0.8996 - learning_rate: 6.2500e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8607 - loss: 0.3319 - precision: 0.8161 - recall: 0.9312\n",
            "Epoch 79: val_accuracy did not improve from 0.82293\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 34ms/step - accuracy: 0.8607 - loss: 0.3319 - precision: 0.8162 - recall: 0.9312 - val_accuracy: 0.8221 - val_loss: 0.4282 - val_precision: 0.7813 - val_recall: 0.8947 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8608 - loss: 0.3307 - precision: 0.8165 - recall: 0.9309\n",
            "Epoch 80: val_accuracy did not improve from 0.82293\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8608 - loss: 0.3307 - precision: 0.8165 - recall: 0.9309 - val_accuracy: 0.8223 - val_loss: 0.4273 - val_precision: 0.7806 - val_recall: 0.8966 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8602 - loss: 0.3312 - precision: 0.8159 - recall: 0.9304\n",
            "Epoch 81: val_accuracy did not improve from 0.82293\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.8602 - loss: 0.3312 - precision: 0.8159 - recall: 0.9304 - val_accuracy: 0.8226 - val_loss: 0.4268 - val_precision: 0.7800 - val_recall: 0.8985 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8602 - loss: 0.3300 - precision: 0.8157 - recall: 0.9307\n",
            "Epoch 82: val_accuracy improved from 0.82293 to 0.82312, saving model to best_model_82_0.8231.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.8602 - loss: 0.3300 - precision: 0.8157 - recall: 0.9307 - val_accuracy: 0.8231 - val_loss: 0.4281 - val_precision: 0.7821 - val_recall: 0.8958 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8623 - loss: 0.3292 - precision: 0.8180 - recall: 0.9319\n",
            "Epoch 83: val_accuracy did not improve from 0.82312\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 33ms/step - accuracy: 0.8623 - loss: 0.3292 - precision: 0.8180 - recall: 0.9319 - val_accuracy: 0.8229 - val_loss: 0.4275 - val_precision: 0.7811 - val_recall: 0.8973 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8619 - loss: 0.3288 - precision: 0.8173 - recall: 0.9323\n",
            "Epoch 84: val_accuracy did not improve from 0.82312\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 31ms/step - accuracy: 0.8619 - loss: 0.3288 - precision: 0.8173 - recall: 0.9323 - val_accuracy: 0.8228 - val_loss: 0.4281 - val_precision: 0.7817 - val_recall: 0.8957 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8608 - loss: 0.3288 - precision: 0.8167 - recall: 0.9306\n",
            "Epoch 85: val_accuracy improved from 0.82312 to 0.82322, saving model to best_model_85_0.8232.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 31ms/step - accuracy: 0.8608 - loss: 0.3288 - precision: 0.8167 - recall: 0.9306 - val_accuracy: 0.8232 - val_loss: 0.4296 - val_precision: 0.7810 - val_recall: 0.8983 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8626 - loss: 0.3276 - precision: 0.8178 - recall: 0.9330\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.82322\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 33ms/step - accuracy: 0.8626 - loss: 0.3276 - precision: 0.8178 - recall: 0.9330 - val_accuracy: 0.8226 - val_loss: 0.4291 - val_precision: 0.7806 - val_recall: 0.8975 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8612 - loss: 0.3300 - precision: 0.8167 - recall: 0.9314\n",
            "Epoch 87: val_accuracy did not improve from 0.82322\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.8612 - loss: 0.3300 - precision: 0.8167 - recall: 0.9314 - val_accuracy: 0.8230 - val_loss: 0.4290 - val_precision: 0.7816 - val_recall: 0.8966 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8613 - loss: 0.3289 - precision: 0.8175 - recall: 0.9304\n",
            "Epoch 88: val_accuracy improved from 0.82322 to 0.82329, saving model to best_model_88_0.8233.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 33ms/step - accuracy: 0.8613 - loss: 0.3289 - precision: 0.8175 - recall: 0.9304 - val_accuracy: 0.8233 - val_loss: 0.4289 - val_precision: 0.7818 - val_recall: 0.8969 - learning_rate: 1.5625e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8632 - loss: 0.3277 - precision: 0.8191 - recall: 0.9323\n",
            "Epoch 89: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8632 - loss: 0.3277 - precision: 0.8191 - recall: 0.9323 - val_accuracy: 0.8231 - val_loss: 0.4288 - val_precision: 0.7817 - val_recall: 0.8966 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8622 - loss: 0.3274 - precision: 0.8179 - recall: 0.9320\n",
            "Epoch 90: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 34ms/step - accuracy: 0.8622 - loss: 0.3274 - precision: 0.8179 - recall: 0.9320 - val_accuracy: 0.8227 - val_loss: 0.4301 - val_precision: 0.7821 - val_recall: 0.8945 - learning_rate: 1.5625e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8625 - loss: 0.3286 - precision: 0.8180 - recall: 0.9325\n",
            "Epoch 91: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8625 - loss: 0.3286 - precision: 0.8180 - recall: 0.9325 - val_accuracy: 0.8230 - val_loss: 0.4294 - val_precision: 0.7818 - val_recall: 0.8960 - learning_rate: 1.5625e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8621 - loss: 0.3283 - precision: 0.8179 - recall: 0.9318\n",
            "Epoch 92: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.8621 - loss: 0.3283 - precision: 0.8179 - recall: 0.9318 - val_accuracy: 0.8227 - val_loss: 0.4292 - val_precision: 0.7819 - val_recall: 0.8952 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8629 - loss: 0.3283 - precision: 0.8186 - recall: 0.9326\n",
            "Epoch 93: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 34ms/step - accuracy: 0.8629 - loss: 0.3283 - precision: 0.8186 - recall: 0.9326 - val_accuracy: 0.8227 - val_loss: 0.4297 - val_precision: 0.7813 - val_recall: 0.8963 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8625 - loss: 0.3281 - precision: 0.8187 - recall: 0.9313\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 31ms/step - accuracy: 0.8625 - loss: 0.3281 - precision: 0.8187 - recall: 0.9313 - val_accuracy: 0.8230 - val_loss: 0.4296 - val_precision: 0.7818 - val_recall: 0.8962 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8610 - loss: 0.3281 - precision: 0.8164 - recall: 0.9315\n",
            "Epoch 95: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.8610 - loss: 0.3281 - precision: 0.8164 - recall: 0.9315 - val_accuracy: 0.8230 - val_loss: 0.4295 - val_precision: 0.7817 - val_recall: 0.8964 - learning_rate: 7.8125e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8627 - loss: 0.3273 - precision: 0.8186 - recall: 0.9321\n",
            "Epoch 96: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 34ms/step - accuracy: 0.8627 - loss: 0.3273 - precision: 0.8186 - recall: 0.9321 - val_accuracy: 0.8227 - val_loss: 0.4301 - val_precision: 0.7815 - val_recall: 0.8958 - learning_rate: 7.8125e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8613 - loss: 0.3283 - precision: 0.8178 - recall: 0.9299\n",
            "Epoch 97: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.8613 - loss: 0.3283 - precision: 0.8178 - recall: 0.9299 - val_accuracy: 0.8230 - val_loss: 0.4295 - val_precision: 0.7822 - val_recall: 0.8952 - learning_rate: 7.8125e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8635 - loss: 0.3258 - precision: 0.8188 - recall: 0.9338\n",
            "Epoch 98: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 31ms/step - accuracy: 0.8635 - loss: 0.3258 - precision: 0.8188 - recall: 0.9338 - val_accuracy: 0.8232 - val_loss: 0.4295 - val_precision: 0.7827 - val_recall: 0.8947 - learning_rate: 7.8125e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m1910/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8632 - loss: 0.3266 - precision: 0.8190 - recall: 0.9327\n",
            "Epoch 99: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 31ms/step - accuracy: 0.8632 - loss: 0.3265 - precision: 0.8190 - recall: 0.9327 - val_accuracy: 0.8231 - val_loss: 0.4301 - val_precision: 0.7812 - val_recall: 0.8975 - learning_rate: 7.8125e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m1911/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8627 - loss: 0.3260 - precision: 0.8182 - recall: 0.9326\n",
            "Epoch 100: val_accuracy did not improve from 0.82329\n",
            "\u001b[1m1912/1912\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 34ms/step - accuracy: 0.8627 - loss: 0.3260 - precision: 0.8182 - recall: 0.9326 - val_accuracy: 0.8228 - val_loss: 0.4306 - val_precision: 0.7819 - val_recall: 0.8953 - learning_rate: 7.8125e-06\n",
            "Restoring model weights from the end of the best epoch: 88.\n",
            "‚úÖ Ensemble training completed!\n",
            "üìä Evaluating Deep Learning Models...\n",
            "Model 1 Accuracy: 0.8097 (80.97%)\n",
            "Model 2 Accuracy: 0.8401 (84.01%)\n",
            "Model 3 Accuracy: 0.8241 (82.41%)\n",
            "\n",
            "üèÜ DEEP LEARNING ENSEMBLE RESULTS:\n",
            "--------------------------------------------------\n",
            "üéØ ACCURACY: 0.8385 (83.85%)\n",
            "‚öñÔ∏è BALANCED ACCURACY: 0.7603 (76.03%)\n",
            "üìä PRECISION: 0.9017 (90.17%)\n",
            "üîç RECALL: 0.8938 (89.38%)\n",
            "üõ°Ô∏è SPECIFICITY: 0.6268 (62.68%)\n",
            "üìà F1-SCORE: 0.8977 (89.77%)\n",
            "\n",
            "üìã Confusion Matrix:\n",
            "   Predicted:    Dropout  Complete\n",
            "   Actual Dropout:   17086      2031\n",
            "   Actual Complete:   1863      3129\n",
            "\n",
            "üöÄ EXCELLENT DEEP LEARNING PERFORMANCE!\n",
            "üìà Achieved 83.85% accuracy\n",
            "üéØ Very competitive results with traditional ML methods!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Deep Learning Dropout Predictor Ready!\n",
            "üìù Load your CSV file and call: results = dl_predictor.train_and_evaluate(df)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02iUNOkvoevM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}